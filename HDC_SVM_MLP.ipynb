{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a627d7ce-ba93-4f21-a6e3-246e985d2e91",
   "metadata": {},
   "source": [
    "# Training, Fine-tuning, Evaluating, HDC and other models on Malware Classification Task\n",
    "## Xiangsheng Gu & Robert Armen Missirian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c15612-ffd0-4482-bec1-29764e251506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import pyRAPL\n",
    "import random\n",
    "import warnings\n",
    "import linecache\n",
    "import tracemalloc\n",
    "import energyusage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# time measurement\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# data and models\n",
    "from SVM import SVM\n",
    "from MLP import MLP\n",
    "\n",
    "from OnlineHDv1 import OnlineHDv1\n",
    "from OnlineHDv2 import OnlineHDv2\n",
    "from NeuralHDv1 import NeuralHDv1\n",
    "from NeuralHDv2 import NeuralHDv2\n",
    "from flexHD import NeuralHDDev\n",
    "from testcode import NeuralHDSpecial\n",
    "\n",
    "from OnlineHD_model import *\n",
    "from NeuralHD_model import *\n",
    "from malware_data_preprocessing import *\n",
    "\n",
    "# Sets the seed for generating random numbers, which helps replicate runs for debugging purposes.\n",
    "# torch.manual_seed(5)\n",
    "# random.seed(5)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9c6cb-b2b2-4c03-bbe7-a63e7dfd0b05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16956c97-8f84-43a4-920a-7838ea203d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/tracemalloc.html\n",
    "def display_top(snapshot, key_type='lineno', limit=10):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, frame.filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dde6459-4545-432d-9c9c-569603e7ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:\n",
      "x_train -> (8151, 257)\tx_test -> (2717, 257)\n",
      "y_train -> (8151,)\ty_test -> (2717,)\n",
      "This dataset contains 9 classes, and 257 features.\n",
      "Top 10 lines\n",
      "#1: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:316: 734.7 KiB\n",
      "    f = lambda x: x.split(pat, n)\n",
      "#2: C:\\Users\\WillGu\\anaconda3\\lib\\selectors.py:315: 288.1 KiB\n",
      "    r, w, x = select.select(r, w, w, timeout)\n",
      "#3: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1957: 85.1 KiB\n",
      "    stacked = np.empty(shape, dtype=dtype)\n",
      "#4: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:179: 85.1 KiB\n",
      "    return array[key] if axis == 0 else array[:, key]\n",
      "#5: C:\\Users\\WillGu\\anaconda3\\lib\\abc.py:123: 41.2 KiB\n",
      "    return _abc_subclasscheck(cls, subclass)\n",
      "#6: <__array_function__ internals>:5: 3.8 KiB\n",
      "#7: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:223: 3.5 KiB\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "#8: <__array_function__ internals>:4: 3.5 KiB\n",
      "#9: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: 2.6 KiB\n",
      "    return f(*args, **kwargs)\n",
      "#10: C:\\Users\\WillGu\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:153: 1.6 KiB\n",
      "    self._date_conv = _make_date_converter(\n",
      "485 other: 200.3 KiB\n",
      "Total allocated size: 1449.5 KiB\n",
      "Memory Usage (in kilobytes): Current used -> 2140.19921875 KB \t Peak used -> 68538.615234375 KB\n",
      "1449.5185546875\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_dataset(\"Microsoft Challenge BIG 2015\")\n",
    "Classes = 9\n",
    "Features = 257\n",
    "print(f'Shape of input data:\\nx_train -> {x_train.shape}\\tx_test -> {x_test.shape}')\n",
    "print(f'y_train -> {y_train.shape}\\ty_test -> {y_test.shape}')\n",
    "print(f'This dataset contains {Classes} classes, and {Features} features.')\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "display_top(snapshot)\n",
    "\n",
    "currentUsed  = tracemalloc.get_traced_memory()[0] / 1024\n",
    "peakUsed = tracemalloc.get_traced_memory()[1] / 1024\n",
    "print(f'Memory Usage (in kilobytes): Current used -> {currentUsed} KB \\t Peak used -> {peakUsed} KB')\n",
    "total = sum(stat.size for stat in snapshot.statistics('lineno')) / 1024\n",
    "print(total)\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058473a-9914-4051-8616-8644bfee3539",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trainning on OnlineHD, NeuralHD, MLP, SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c639b3-1e46-443d-bb3c-d45dc5e0bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list, \n",
    "                        HDC = True, repetitions = 1, model_select = None,                \n",
    "                        Classes = 9, Features = 257, Dimensions = 1024,\n",
    "                        Learning_rate = 0.02, Epochs = 64, Batch_size = 64,\n",
    "                        Regeneration = 5, FractionDrop = 0.1, \n",
    "                        batchSz2 = 1, ep2 = 6):\n",
    "    \n",
    "    if HDC == True:\n",
    "        # For the training set\n",
    "        x_train = torch.from_numpy(x_train)\n",
    "        y_train = torch.from_numpy(y_train)\n",
    "        # For the testing set\n",
    "        x_test = torch.from_numpy(x_test)\n",
    "        y_test = torch.from_numpy(y_test)\n",
    "    \n",
    "    # initialize all evaluation factors\n",
    "    acc_means = np.zeros((len(ratio_list), ))\n",
    "    acc_medians = np.zeros((len(ratio_list), ))\n",
    "    acc_deviations = np.zeros((len(ratio_list), ))\n",
    "    \n",
    "    cpu_usage_lst = np.zeros((len(ratio_list), ))\n",
    "    memory_usage_medians = np.zeros((len(ratio_list), ))\n",
    "    training_latency_medians = np.zeros((len(ratio_list), ))\n",
    "    energy_consumption_medians = np.zeros((len(ratio_list), ))\n",
    "    \n",
    "    print(f'Training on CPU i9-12900K that has {os.cpu_count()} cores')\n",
    "    # Getting cpu load over 5 minutes\n",
    "    load1, load5, load15, = psutil.getloadavg()\n",
    "    \n",
    "    for idx, ratio in enumerate(ratio_list):\n",
    "        acc_lst = np.zeros((repetitions, ))\n",
    "        Tr_latency_lst = np.zeros((repetitions, ))\n",
    "        kiB_list = np.zeros((repetitions, ))\n",
    "        \n",
    "        data_amount = int(x_train.shape[0] * ratio)\n",
    "        \n",
    "        # CPU load for 1, 5, 15 minutes of measurement\n",
    "        load1, load5, load15, = psutil.getloadavg()\n",
    "        \n",
    "        for repetition in range(0, repetitions):\n",
    "            \n",
    "            if model_select == 'OnlineHDv1':\n",
    "                model = OnlineHDv1(classes = Classes, features = Features, \n",
    "                                   dim = Dimensions, batch_size = Batch_size,\n",
    "                                   lr = Learning_rate)\n",
    "                # if torch.cuda.is_available():\n",
    "                #     print(f'Training on {torch.cuda.get_device_name(0)}\\n')\n",
    "                #     model = model.to('cuda')\n",
    "                #     x_train = x_train.to('cuda')\n",
    "                #     y_train = y_train.to('cuda')\n",
    "                #     x_test = x_test.to('cuda')\n",
    "                #     y_test = y_test.to('cuda')\n",
    "                \n",
    "            if model_select == 'OnlineHDv2':\n",
    "                model = OnlineHDv2(classes = Classes, features = Features, \n",
    "                                   dim = Dimensions, batch_size = Batch_size,\n",
    "                                   lr = Learning_rate)\n",
    "                \n",
    "            if model_select == 'NeuralHDv1':\n",
    "                model = NeuralHDv1(classes = Classes, features = Features, \n",
    "                                   dim = Dimensions, batch_size = Batch_size, \n",
    "                                   lr = Learning_rate)\n",
    "                \n",
    "            if model_select == 'NeuralHDv2':\n",
    "                model = NeuralHDv2(classes = Classes, features = Features, \n",
    "                                   dim = Dimensions, batch_size = Batch_size, \n",
    "                                   lr = Learning_rate)  \n",
    "                \n",
    "            if model_select == 'NeuralHDSpecial':\n",
    "                model = NeuralHDSpecial(classes = Classes, features = Features, \n",
    "                                        dim = Dimensions, batch_size = Batch_size, \n",
    "                                        trainopt = 2, bestinclass = True, lr = Learning_rate)\n",
    "                \n",
    "            if model_select == 'SingleStop':\n",
    "                model = NeuralHDDev(Classes, Features, Dimensions, \n",
    "                                    trainopt = 2,bestinclass = True, multiencoder = True)\n",
    "            \n",
    "            # start training latency\n",
    "            training_start = time.time() \n",
    "            \n",
    "            if model_select == 'OnlineHDv1' or model_select == 'OnlineHDv2': \n",
    "                # Start tracing Python memory allocations\n",
    "                tracemalloc.start()\n",
    "                model.fit(x_train[:data_amount, :], y_train[:data_amount], epochs = Epochs)\n",
    "                # measure in kilobytes\n",
    "                total_allocated_memory = sum(stat.size for stat in snapshot.statistics('lineno')) / 1024\n",
    "                # Stop tracing Python memory allocations\n",
    "                tracemalloc.stop()\n",
    "\n",
    "            if model_select == 'NeuralHDv1' or model_select == 'NeuralHDv2' or model_select == 'NeuralHDSpecial': \n",
    "                # Start tracing Python memory allocations\n",
    "                tracemalloc.start()\n",
    "                model.fit(x_train[:data_amount, :], y_train[:data_amount], \n",
    "                          epochs = Epochs, regenloops = Regeneration, fractionToDrop = FractionDrop)\n",
    "                # measure in kilobytes\n",
    "                total_allocated_memory = sum(stat.size for stat in snapshot.statistics('lineno')) / 1024\n",
    "                # Stop tracing Python memory allocations\n",
    "                tracemalloc.stop()\n",
    "                \n",
    "            if model_select == 'SingleStop':\n",
    "                # Start tracing Python memory allocations\n",
    "                tracemalloc.start()\n",
    "                \n",
    "                # Initial training\n",
    "                model.fit(x_train[:data_amount, :], y_train[:data_amount], \n",
    "                          epochs = Epochs, \n",
    "                          regenloops = Regeneration, \n",
    "                          fractionToDrop = FractionDrop, \n",
    "                          learningrate = Learning_rate, \n",
    "                          batch_size = Batch_size, \n",
    "                          testsample = 1)\n",
    "                \n",
    "                # stop training\n",
    "                model.fit(x_train[:data_amount, :], y_train[:data_amount], \n",
    "                          epochs = ep2, \n",
    "                          regenloops = Regeneration, \n",
    "                          fractionToDrop = FractionDrop, \n",
    "                          learningrate = Learning_rate, \n",
    "                          batch_size = batchSz2, \n",
    "                          testsample = 1)\n",
    "                \n",
    "                # measure in kilobytes\n",
    "                total_allocated_memory = sum(stat.size for stat in snapshot.statistics('lineno')) / 1024\n",
    "                # Stop tracing Python memory allocations\n",
    "                tracemalloc.stop()                \n",
    "\n",
    "                    \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "            training_latency_sec = training_end - training_start\n",
    "            \n",
    "            y_pred = model(x_test)\n",
    "            binary_eval = [y_pred[i] == y_test[i] for i in range(len(y_test))]\n",
    "            accuracy = sum(binary_eval) / len(y_test)\n",
    "            \n",
    "            acc_lst[repetition] = accuracy \n",
    "            Tr_latency_lst[repetition] = training_latency_sec\n",
    "            kiB_list[repetition] = total_allocated_memory\n",
    "\n",
    "            \n",
    "        avg = np.mean(acc_lst)\n",
    "        median = np.median(acc_lst)\n",
    "        std = np.std(acc_lst) \n",
    "        Tr_latency_median = np.median(Tr_latency_lst)\n",
    "        kiB_median = np.median(kiB_list)\n",
    "        \n",
    "        acc_means[idx] = avg\n",
    "        acc_medians[idx] = median\n",
    "        acc_deviations[idx] = std\n",
    "        training_latency_medians[idx] = Tr_latency_median\n",
    "        memory_usage_medians[idx] = kiB_median\n",
    "        \n",
    "        # Getting cpu load over 5 minutes for each ratio\n",
    "        cpu_usage = (load5 / os.cpu_count()) * 100\n",
    "        cpu_usage_lst[idx] = cpu_usage\n",
    "    \n",
    "    print(f'{model_select} Report:')\n",
    "    print(f'Classes -> {Classes} \\t Features -> {Features} \\t Dimensions -> {Dimensions}')\n",
    "    print(f'Learning Rate -> {Learning_rate} \\t Epochs -> {Epochs} \\t Batch size -> {Batch_size}\\n')\n",
    "    if model_select == 'NeuralHDv1' or model_select == 'NeuralHDv2' or model_select == 'NeuralHDSpecial':\n",
    "        print(f'Regeneration -> {Regeneration} \\t FractionDrop -> {FractionDrop}\\n')\n",
    "        \n",
    "    print(f'Data Usage Ratio: {ratio_list}\\nAverage Accuracy: {acc_means}\\nMedian Accuracy: {acc_medians}')\n",
    "    print(f'Accuracy Deviation: {acc_deviations}\\nTraining Latency: {training_latency_medians}')\n",
    "    print(f'CPU Usage(%): {cpu_usage_lst}\\nMemory Usage(KiB): {memory_usage_medians}')\n",
    "    if model_select == 'SingleStop':\n",
    "        model.plot()      \n",
    "    return [ratio_list, acc_means, acc_medians, acc_deviations, training_latency_medians, cpu_usage_lst, memory_usage_medians]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee4e992-b10c-4927-aeba-b4eb8e904cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "OnlineHDv1 Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 1e-05 \t Epochs -> 64 \t Batch size -> 64\n",
      "\n",
      "Data Usage Ratio: [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "Average Accuracy: [0.1409643  0.80813397 0.80092013 0.89020979 0.88306956 0.92933382\n",
      " 0.92528524 0.92716232 0.93695251 0.9444608  0.93018035 0.94490246]\n",
      "Median Accuracy: [0.1409643  0.80916449 0.84596983 0.90191388 0.90651453 0.93099007\n",
      " 0.92749354 0.92730954 0.94184762 0.94589621 0.93099007 0.94239971]\n",
      "Accuracy Deviation: [0.         0.00522855 0.12524119 0.02270028 0.05522611 0.00888832\n",
      " 0.0165918  0.00482823 0.019795   0.00633104 0.004894   0.00754473]\n",
      "Training Latency: [0.02400041 0.42824888 0.81799829 1.57624733 2.25226057 2.94099438\n",
      " 3.55674291 4.22399235 4.96999168 5.44524038 6.18023896 6.63398802]\n",
      "CPU Usage(%): [0.         0.         0.08333333 0.33333333 0.91666667 0.875\n",
      " 0.95833333 1.70833333 1.79166667 3.91666667 4.16666667 4.41666667]\n",
      "Memory Usage(KiB): [1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469]\n"
     ]
    }
   ],
   "source": [
    "Ratio_list = [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'OnlineHDv1',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = 0.00001, Epochs = 64, Batch_size = 64,\n",
    "                              Regeneration = 5, FractionDrop = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c5fce0-a307-43b1-a9f1-861d068861aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "OnlineHDv2 Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.00035 \t Epochs -> 64 \t Batch size -> 64\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
      "Average Accuracy: [0.83143173 0.80033125 0.91310269 0.91733531 0.91689364 0.93444976\n",
      " 0.93341921 0.93584836 0.9367317  0.93702614 0.9423629 ]\n",
      "Median Accuracy: [0.8522267  0.87154952 0.91847628 0.9241811  0.92730954 0.93595877\n",
      " 0.9431358  0.93853515 0.94350389 0.94000739 0.94552815]\n",
      "Accuracy Deviation: [0.05968566 0.12162392 0.01945567 0.01657073 0.0232479  0.01341901\n",
      " 0.01958821 0.01448656 0.02006847 0.01598422 0.00944857]\n",
      "Training Latency: [0.48274684 0.92849386 1.70148921 2.46473432 3.08673036 3.85347462\n",
      " 4.62046993 5.29496574 5.96221197 6.69045758 7.21920347]\n",
      "CPU Usage(%): [13.83333333 14.         13.54166667 12.875      12.91666667 12.25\n",
      " 10.70833333 14.25       12.91666667 13.125      11.41666667]\n",
      "Memory Usage(KiB): [1449.34375 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375\n",
      " 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375]\n"
     ]
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'OnlineHDv2',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .00035, Epochs = 64, Batch_size = 64,\n",
    "                              Regeneration = 5, FractionDrop = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5e1257-c916-4597-bc20-58d7f5f47504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "NeuralHDv1 Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.001 \t Epochs -> 5 \t Batch size -> 32\n",
      "\n",
      "Regeneration -> 25 \t FractionDrop -> 0.4\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
      "Average Accuracy: [0.81924917 0.81829224 0.76190652 0.89955835 0.91479573 0.91104159\n",
      " 0.90419581 0.92469636 0.89988958 0.93191019 0.91972764]\n",
      "Median Accuracy: [0.81818181 0.85756347 0.77585572 0.90209791 0.91700405 0.91221938\n",
      " 0.9146117  0.92510122 0.90136179 0.93687889 0.91994846]\n",
      "Accuracy Deviation: [0.02230076 0.08700262 0.11133544 0.01602654 0.00734124 0.01632683\n",
      " 0.02624972 0.00576845 0.01832815 0.01382821 0.01771895]\n",
      "Training Latency: [ 1.83523858  3.33472872  6.1296562   9.01996279 11.71784198 14.66868901\n",
      " 17.43528354 20.30304301 23.15546739 25.93422616 28.81345642]\n",
      "CPU Usage(%): [10.95833333 12.75       19.04166667 18.79166667 15.125      10.625\n",
      "  9.08333333  5.91666667  4.79166667  7.29166667  4.41666667]\n",
      "Memory Usage(KiB): [1449.34375 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375\n",
      " 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375]\n"
     ]
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'NeuralHDv1',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .001, Epochs = 5, Batch_size = 32,\n",
    "                              Regeneration = 25, FractionDrop = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9057039a-bf8b-48f5-aa9e-94d45bb42a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "NeuralHDv2 Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.001 \t Epochs -> 5 \t Batch size -> 32\n",
      "\n",
      "Regeneration -> 25 \t FractionDrop -> 0.4\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
      "Average Accuracy: [0.83687891 0.85160104 0.84556496 0.87338977 0.87935223 0.91420685\n",
      " 0.91177769 0.90846522 0.91615751 0.90835481 0.8889216 ]\n",
      "Median Accuracy: [0.84946632 0.87062937 0.86897314 0.89565697 0.88479942 0.91626796\n",
      " 0.91479573 0.91405964 0.92749354 0.90982702 0.92988589]\n",
      "Accuracy Deviation: [0.0392555  0.07266616 0.08086489 0.05455608 0.04540253 0.02107274\n",
      " 0.01998094 0.03099699 0.0241381  0.01871216 0.08387262]\n",
      "Training Latency: [ 1.4048568   2.56269193  4.53706026  6.35863924  8.24099267 10.41164136\n",
      " 12.50537539 14.56478238 16.63876629 18.59641671 20.5607549 ]\n",
      "CPU Usage(%): [4.25       4.16666667 3.83333333 3.5        3.29166667 4.33333333\n",
      " 4.45833333 4.375      5.08333333 4.125      5.04166667]\n",
      "Memory Usage(KiB): [1449.34375 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375\n",
      " 1449.34375 1449.34375 1449.34375 1449.34375 1449.34375]\n"
     ]
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'NeuralHDv2',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .0001, Epochs = 5, Batch_size = 32,\n",
    "                              Regeneration = 25, FractionDrop = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e6a732-d890-41d9-b7b1-29f305dad392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "NeuralHDSpecial Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.0001 \t Epochs -> 35 \t Batch size -> 1\n",
      "\n",
      "Regeneration -> 5 \t FractionDrop -> 0.0\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "Average Accuracy: [0.89050424 0.91818182 0.93584836 0.94490247 0.95443504 0.95616488\n",
      " 0.95914611 0.9617961  0.96330512 0.96429886 0.96514539]\n",
      "Median Accuracy: [0.89124033 0.91921237 0.93485463 0.94571218 0.95491353 0.95564961\n",
      " 0.95951417 0.96227458 0.96282667 0.9646669  0.96577108]\n",
      "Accuracy Deviation: [0.00530111 0.00446862 0.00482992 0.00301736 0.00391176 0.00258922\n",
      " 0.00324639 0.00177888 0.00223303 0.00184762 0.00111697]\n",
      "Training Latency: [ 16.62583041  33.0905031   27.13606453  40.24942851  53.61204386\n",
      "  67.15922856  79.49521816  93.79903233 105.97963178 120.29027951\n",
      " 132.60760498]\n",
      "CPU Usage(%): [0.75       0.5        0.58333333 1.41666667 0.45833333 0.91666667\n",
      " 0.66666667 0.33333333 0.91666667 0.79166667 0.875     ]\n",
      "Memory Usage(KiB): [1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469]\n"
     ]
    }
   ],
   "source": [
    "Ratio_list = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'NeuralHDSpecial',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .0001, Epochs = 35, Batch_size = 1,\n",
    "                              Regeneration = 5, FractionDrop = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f78c3c0-5821-48b1-a0b6-a92df2be0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "SingleStop Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.0001 \t Epochs -> 45 \t Batch size -> 1\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "Average Accuracy: [0.88450497 0.91453809 0.93496504 0.94747884 0.95421422 0.95550239\n",
      " 0.9583364  0.96128083 0.96297387 0.96415164 0.96503497]\n",
      "Median Accuracy: [0.8840633  0.9146117  0.93522269 0.94755247 0.9547295  0.95601764\n",
      " 0.95730585 0.96190652 0.96282667 0.96429884 0.96503496]\n",
      "Accuracy Deviation: [0.00808847 0.00384189 0.00171885 0.00189145 0.00181954 0.00225355\n",
      " 0.0021637  0.00203464 0.00160599 0.00238639 0.00220832]\n",
      "Training Latency: [  8.66883373  16.71459293  33.27832735  50.32540774  66.22437894\n",
      "  81.4698509   99.37581825 113.96129167 130.21949053 148.31722891\n",
      " 164.00917006]\n",
      "CPU Usage(%): [0.25       0.25       0.33333333 0.45833333 1.41666667 0.29166667\n",
      " 0.45833333 1.125      0.29166667 0.75       0.91666667]\n",
      "Memory Usage(KiB): [1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyj0lEQVR4nO3de3gc9X3v8fd39qK7ZMmW73djsI3BhgiDSYCkKWCSACVJE2hOQjhJKX2gJ23StLQ9bdPkpElK0jY9oeUhKSVNISQ5gYS2LpcQGig0YBt8B2Phm2TJlmRZknVd7e7v/DEzu7M3abVaS9rx9/U8fqydizSjtT/66ju/+Y0YY1BKKeVf1nQfgFJKqbNLg14ppXxOg14ppXxOg14ppXxOg14ppXxOg14ppXwuON4GIvIQ8AGgwxizPst6Ab4JvA8YBD5pjHnNWbfFWRcAvmOM+Wo+BzVnzhyzfPnyfM9BKaXOeTt27OgyxjRmWzdu0AMPA98C/jnH+huA1c6fy4F/AC4XkQBwP3At0ApsE5EnjTH7x/uCy5cvZ/v27XkcmlJKKQAROZpr3bitG2PMC0D3GJvcDPyzsf0SmCUiC4BNQLMx5pAxJgI85myrlFJqChWjR78IaPG8bnWW5VqulFJqChUj6CXLMjPG8uyfROROEdkuIts7OzuLcFhKKaWgOEHfCizxvF4MtI2xPCtjzIPGmCZjTFNjY9brCUoppQpQjKB/EviE2K4Aeo0x7cA2YLWIrBCRMHCrs61SSqkplM/wyu8D7wbmiEgr8OdACMAY8wCwFXtoZTP28Mo7nHVREbkHeBp7eOVDxph9Z+EclFJKjWHcoDfG3DbOegPcnWPdVuwfBEoppaaJ3hmr1DmirWeInsHIhPYxxhCL5/fMiraeIQZGooUcGmM9FyMai/MvvzzKgRNnGBiJ0tI9SN/waGL9a8dO09E3PO7nP94zlLF8JBob99ie2tvO4a4BBkaiHDs1mPPzp5/77tYeXm7uAiAeN3T0DdPSPUg0Fs/5OQYjhX3/xpPPDVNKjSkeN1hWtkFWhTszPEplOEigyJ83X4ORKE/ubOON9j7+8IY1VIaDjERjBEQIBiz6hkepLQ8BdhD9cHsr7b1D/K/3riZuDOGAxcGOfmrKgyyoq2AkGuPYqUFWzKkiGMheXx3uGuDtjn4uXFRLJBrnr54+wPsvWsB/HuggEo3zG5cv47Ll9bT3DrPj6GlePdyNJXDJ0nqWza5kx9HTXLFyNvvaeunoG6G2IsT582rYvGo2Ld2DvP/vXqQsFOCP37eGUMDizHCUI10DvPuCuVy2vJ64gbdOnuFH21t41+pGggHhG88coOtMhN+4fCnRWJxPXLmc779yjBcPdrFqbjV/fuM6ykMBdhzt5mPfeYWLFtXxFzet56l9J9hy4XwGI1HWL6qjPBSgq3+EB184xPNvdnDp0no+vnkZZUGLL299g5ebT3HB/BosS/jyr61n/aI6ItE4e4738NBLR/j33e0AiIAxUB6yuP3K5RzpGuDpfSeZUx3mTz+wjqOnBvn33e28Y3k9n732fE70DnOyb5ifv9nBI68c4+rzG2msLuPq8+fw1N4T7Gzp4eefezedZ0Z4al87u1p62bhkFp++agUiwi/e6uSuf3mNxpoyZlWEONo9yFduuYjHX2/lAxcvZCgSY2Akyt62Xp57o4Ovfehiugci/OvuNna39mIJ/PH71vKt55vpGbR/OF24sJZHf/MK6ipCHOrs5w/+3262rJ9Pe+8wrxw+xQ/u3ExVWXGjWWbiE6aampqM3hmb2/BojH1tvVyypJ64MQQsQUQSVcvCugosS4jG4kTjhvJQILHv1j3tBCzh8hUNdJ4ZYfW8GgBO9Y9QUx4iFBCe3neSH21vYVF9BRcurGXLhQuoKgtwom+YxfWVRKJxHvjF285/xF4OnDjDs5+9mriBe3+8m92tvRhjmFNTxpzqMna29PAXN13IjRsW8ugrx/jB9hY+dOkiHn3lGO88bw57WnsJBoTv3N5ENG748r+9wROvH+fSZbP4zu2XEYsZfrSjhSdeP87XPnQxaxfUct/TB3ipuYvPvHc16xfV8Wc/3csVK2dz1eo5/Puedk71R6ivDNFYU8a7VtujuLr6R2haVs9LzafYfbyH69bN57y51QDE4oa9x3s5cmqAo6cGeeSVo5zsGwHgtk1L+LMPXMgtf/8ScWN4x7IGHtt2jOvXzae5s5+W7kFGonaVtqShguOnhwhaFpFYnKAlXDC/hoMn+4nE4sx1vicrG6v40DsWU1MW5GBHP/Pryrn7kdcYjMQIBYTa8hCnBuzqOxywKAvZwVxTFuSMUzlWhe33dSAydlV6/29cyoMvvM2hzgHqq8Ic605WpW5wBi0h5skC98PGmjLm1Zax93gfQOLrr19Uy97jfWxeOZuPXraEP/3pXgDODEcJBy0i0WTVurShki3r5/PjHa30DI3StKyevcd7E8ddFQ5w08aFHD01yMtvn+J/v38tn75qJf/3uYN849m3APjstecTsIRY3DC/rpyf7T/JM/tPUlMe5GOXL+Opve0ccartjUtmsb+tj7ULaznU0Z/4fv3q2nnsbDlNNG4SoWu/v0v50fYWonHDnOoyuvpH2LxyNsd7hugdGmVWZYjugQjxuKGmPMSJvmFCAWE0ZhLfw5BlsXR2Jc0d/QBcvLiOmzYs5J9eOsLxniFWNlbxySuXE4nG+dpTbzKvtpwl9ZXsau1hJBpP/Nb0ySuX8+c3rsOeWWZiRGSHMaYp6zoN+tLxzZ8d5NFXjzIwEqN/JMpHmhbzy0PdBCzhI01L2HG0m5+90cGy2ZWEAxZHTg0wGjMsn13JXdes4tZNS3nHl57l1ECEcMAOondf0MjBk/0c7xnixg0LWb+wlq/8x5ssqCvnzHCU/pEoGxbXsaqxmsdfP8616+bR1jPEvrY+ApYQDlgMjca4+z2r+Nn+Dg519fP+ixYQsCxO9A3R3jNMJBZnYCTKF266kM/9cBcGO1jn15Zzom+YWZUh+oZGWTO/lsFIlNbTQ9xw0QK27mnHEogbEv8R/uKmCzlyaoB/eukIc6rDdPVHEmEFYIl9s0ZdRYjeoVGMsf8jgr3NNec38ou37Ps0rljZwGN3bmZfWy+3P7SNrv6RxPf60qWz+MMta3j+QCcP/OJtzptbTXNHP2VBi5FonCtWNrCrpZcNS+q4ePEs3rGsnt7BUf7xvw5z9flziBtY1VjNgRN9vHWyn4sX17F8ThUvHuxkKBJj+9HTnBlO/TV9fm05f/2RDTy5q42X3z7FN2/dyN62PjYtb2BJQwX/uquN1472sHZBDZcuq2fdglosEXa19nC4a4CNS2bxUnMXF8yvZeOSWfQMRfjYt1/hYEc/AUv4+49dytWrG3m70z6PinCAhqow33+1he6BEYKWhSXC/7hiKbuP9xKyLDYunUVlKEDv0CgHTp7ht/9lB7dtWsrnr7+Ax187zv/+yV6GRmOsnlvNQ5+8jM/+cCeHuwb5+49dyuGufsqCAf7+P5s50jXI2oW1fP3DF7N6Xg29Q6P8YNsxyoIBbrhoPnNryjHGcN6f/Ad3XbOSz1+/hk89vI23O/v5zu1NnDe3JuP/w+mBCHUVISxLGB6NcfBkP6GgsGZ+LT/e0crnfrSLhqowf/aBdUTjhg9duggR+4fFwy8foTxk8d2Xj/DWyX4W1JXzw9/azKJZFfzBj3fz1N4TbF41m9MDEf7sxnXUlIcQYCAS5R9fPMxnrzufgyf7aawpY3F9BdG4oSxo8e0XD/OeCxq5ZGk9ADuOnuYf/rOZL968noWzKgB4/s0OHn75CL1Do6yZX8Nvv3sVD/3XYWrKQ3zuuvMLCnnQoC95/767ncNd/Xz9mbe4YmUDqxqrGYrEePz148yqDDG/tpw3T5whHLS448rl7G/vozwU4Ly51VSEAvz8zQ52tvTwvU9t4uP/+CpNy+pZt7CWilCAR185xmUrGghYwrP7T1IZDnD5iga+/YkmLBEef/04v/+jXQBcvqKBtzv7mV1Vxj2/ch5XrZ6DZQmf/u52Xj3cTTho8dDtl/Gu1XNSjv/AiTO8/+9eJBo3LGmo4Pu/eQU7jp7m+gvnc7xniNlVYf7TCVSAL9x0IVesnM0vD53i+QMdlAUs3rNmLh/8h5f5nV9ZzfNvdlBTHuThOzbxzP4T7Dh6mg9espgndx2nfyTK7193AbOry4jG4rT3DvOT148DsO3oaV54q5PbNy9jbm059z19gJ/c/U62He7my1vf4Bu/voGLF9exqL6CyrD9q3MkGudvfvYWj/zyKB/fvIz3rp3H/rY+Pnb50oL/QwIMjETZ3dpL/0iUxfUVPLv/JNdfOJ8L5mcG2mTsaunh9364kz+4/gK2rF8w6c+X3qY70TvMU3vb7d9OykMMj8aIxg3VBbYemv7Ps1x34Xz+8paLuPIrz3HZiga+eeslBX2uH2w7xoUL61i/qC7nNo+8cpQ/eWIv3/5EE9eumwfYvXJjKHo78mzToC9h3QMRLv3SswCsXVDLT+6+krJggFjc8N2Xj3D1+XNY1VhN33CUoCVZe3ttPUNc+dWf88krl/Pwy0f4u9su4aYNC1O26R0c5V1/9XP6R6L8x2euYs38WsD+R//7P9pN6+lBvvepywkHM/vLLx7s5Le+t4P7PryB91+cPUx+eegUZ4ajbFrRQF1FqKDvxSVffIYPXLyQ5944yeZVc/jGRzZMaP+RaIzdrb00LatnIBLjyq88x7svmEt9ZYjHXz/Oni9cn3NfY8ykgl3l59q//gXnza3mKx+8iI1ffJZ7b1jDXdesOmtfLx43vN3Zn2hhlrKxgl4vxs4gh7sGWDSrIiVM3+60e35fuHEdt1yymLKg3ZcNWML/fNeKxHZjhef82nLKghYvHLRbFovrKzK2qasM8eVbLqKjbzgR8gAiwjc+smHMoLtqdSO7/vw6QjkuMgJcsXJ2znX5aqgK0z0QoWsgwpzq8IT3LwsGuGx5AwDVZUGuOr+RnS09nDe3msX1lWPuqyE/Neqd9/iN9jOAXdycTZYlvgj58ejwyhmid2iU6//2Bf5y6xspyw93DgDwnjVzqassrBK2LGH57CoOOZ8rW9AD3LRhIZ++amXWdeMF3VghXywNVWFaTg8SicaZXUDQp1s9t5qW04M0d/SzJMf3RE2t+soQPYOjvNFuX/xdW+RW1rlKg36GeO3YaSLROI++cozv/fIo/7HHHk72dlc/4YA1bsU5nhVzqgAoC1o0VpdN+ninQ0NVmIMn7d9wZldN/hzOm1uNMXCse5AlDZP7/qriaKgK0z0Y4c0TfcyuCtNYU5r/Vmcabd3MEDuOnCZgCQbDn/7EHqp25Kvv51DnAMtmV056PPlyJ+gX11eUbBuioSrM0Kg9JK8YFb07tBLQin6GqK8Mc3ogwsGOfs6fV1Oy/1ZnGq3oZ4htR7q5cGEtf/PRjdRVhKgtt38GH+4aSFTjk7EyEfSlW7nWVybDvRgV/Yo5Vbg/P7WinxnqK8NE44Y32vsSxYmaPA36s6Cjb5gbvvkih7sGEsvae4e4//nmrLd6j8bi7Grt4R3L6vnAxQu59bIljETjRGNxjp4aYGVjdcY+E+Wt6EtVQ5Un6ItQ0ZcFAyx1Ar6UfwD6Sb3zHg+Pxlk+W9+TYtGgPwu2HTnNG+197Gw5nVj24x2t3Pf0Adp6U+fkeOXQKTZ/5TmGR+OJESHloQAj0TjHugcZjRlWNhahom+sQgSWzy7dKskb9N6PJ8Nt35TyD0A/aahKDjhYVsL/Vmca7dGfBQc77KFhHX0j/HTncWdOC7u67x0cZdGsZKi8eLCL04OjfPmW9fzqWvuGjUrn1vYjp5xRMrMmH0Jzqsv4/m9eMebNIzOdG+41ZcGUaR0m45rzG+kdGi363CKqMLM87blitCyVTf91nwXuyJCOMyM88sox6qvCiecq9g6Npmx75NQAi+sr+NjlyxLLKpyg7zpjz3VSrBAqxlj26eQGfTHaNq6Pb17OxzcvL9rnU5PT4An6pXrdpGg06M8Ct6I/2TdMe+8QJ/qGKXNuguodSp0m9lj3YMY/aLdadSe1qiorTvVa6pJBr0Pu/Mq94D6/tjxR8KjJ0x59kY3G4omLsPvb+hiNGSLReGICq4yKvmsgo2/utm5OOZNsufOunOsSQV+k/ryaeWrK7ampl+mF2KLSoC+yo86MkUFLOOQZdePyTo/aMxihbzia8Y+6wqno3dkUqzToAfv7Uh6ytKL3McsSFs2qOOtTH5xrNEHG8eaJPr7182a+/usbxr0A+Iu3OvkbZ/7sS5bOYtuR0xnb9Hgq+qPO/Nnpowsq0lo3+iusTUS478MbWKO3xfvaD39rM9XlGk3FpBX9OP7pv47wb7vb2Z4ltNM99uox3jzRx6+uncuVq5JT9a5bUEsoIMyqDKW0btxRNekVfbl7MbY/QiggWWeMPFfduGHhOTEJ1blsfl15wdMcq+w0QcYwGovz1L4TALx6+NS427ecHmTTitl85/bLWOSMy64pC/Kpd63gtk1LaagK0+tp3bjPn0y/GFsZTrZutD+vlJosDfoxvNTcRe/QKOGgxS8Pd6es23akm2vuez7lgcAt3UOJOVPmOpMxLZxVwYfesZgv3rw+8dQj16tHullYV57REnJbN90DkcTj4pRSqlB5Bb2IbBGRAyLSLCL3ZllfLyJPiMhuEXlVRNZ71h0RkT0islNEpu1pIj/YdozHX2vNuT4eN5xMe5L8C291UR6yuPWyJexs6WF4NPlszvuePsDRU4Psau0BoG94lN6h0cScKY2JoC9P7DOrIkSPM7zyxYOdvHiwi9uvXJ5xLG7Qx+KGSv0VVik1SeMGvYgEgPuBG4B1wG0isi5tsz8GdhpjLgY+AXwzbf17jDEbcz39ZCo88soxHtvWkrLswIkznBm2K+xvPd/M5X/5HK2nkw9OHo7GqC4LcdXqRiLROLtaehLr6p254d1RNK3dQwAsceZMmVtjB/xCz12tsyrDiYr+/uebWVxfwSffuTzjWMs9VbxW9Eqpycqnot8ENBtjDhljIsBjwM1p26wDngMwxrwJLBeReUU90kkajMQY8TyZ3hjD9X/7Ahd94RlOD0R4Zr/di+8eiKRsYwlsWt6ACLzqad+4N3Z0D0TY8rcv8Dc/s0fbLGmwg312VZhVjVU0La9P7FNXEUr8YOjoG2HjklmJJ0Z5VXhaOdqjV0pNVj5BvwjwlsKtzjKvXcAHAURkE7AMWOysM8AzIrJDRO6c3OEWbnAkyoin9eIN/S/+236GIvY6b788HgdLhLrKEBfMq+EVT9C7c3Ic7hrgzRNneHb/SSBZ0VuW8Nzn3s0tlyxO7FNXEeLMcJRY3DASjeccrhkKWIQC9qQJelesUmqy8gn6bDP/p8+1+1WgXkR2Ar8DvA64VynfaYy5FLv1c7eIXJ31i4jcKSLbRWR7Z2dnXgc/EYOjsZQeu3unKkDr6UGGR+3g9z4SL+5U9GDPE7Pj6GlGY/Z2s5zWzYETZxLbV5cFE8uzcZ/r2jc0yvBoLDEtQjbuD4EKreiVUpOUT9C3Aks8rxcDbd4NjDF9xpg7jDEbsXv0jcBhZ12b83cH8AR2KyiDMeZBY0yTMaapsbFxoucxrsGRWCLMgZTRMv0jyR8C3vni4yb5rNRNKxoYGo2x53gvkPyBcOBkMujHe3qT+0Ogd2h0zIoeku0b7dErpSYrn6DfBqwWkRUiEgZuBZ70biAis5x1AJ8GXjDG9IlIlYjUONtUAdcBe4t3+PkZjcWJxOIMR5MVfb8T9FXhAIORaOIRdd5fVYwxuLm9aYU9V/w2p33j/kDoPGNPU7CkoYILF449BbBb0fcMjTISHbuid8fSa49eKTVZ46aIMSYqIvcATwMB4CFjzD4RuctZ/wCwFvhnEYkB+4FPObvPA55wqtwg8Kgx5qnin8bYBp3+e7bWzbzacvqGozkqeoPlJP2c6jIaqsIc6x5MrPP6t9+5KhHOubhBf3ogwmjMZL0Q63Krfe3RK6UmK69y0RizFdiatuwBz8f/DazOst8hYMMkj3HShhJBH3eqdElU9HNry2jvHSbu5Hbck98G8D6Te35tOSecJ0R5t6urCCVCfCxudX560B7ZUx7KXdFXaEWvlCqSc+LO2IFIsh8fcS6muj36ebXlibYNpFbqcUOiogd7Do72RNAnt5tXm99sim54n3aGWObTutGKXik1WedE0LsVPZC4IHvGE/Re3o5M3NOjBzvoTzh3z3q3c2+OGo97gbXXqejL8rgYW1GkR+Yppc5d50TQe0fYuGPp+50evTsnjctbqRtPjx5gQW053QMRhkdjKb38uflW9E5ou1MVj9W6SfbotXWjlJqccyLoB0czK/r+kVEClmQ8fzSloo9ntm7AvqvV26NP/60gl/Kw/e1Otm7Gr+jHu8CrlFLjOSeCPqV1E01W9NVlwYynN8XTRt14WzcL6uzpDdp7h1K2S/+tIJdwwMIS+8lSMHZFn+zRa0WvlJoc3wf9U3vbUx7f5w6j7B+JUV0WzHjAQWqPnpQboObX2YF+om84paKfn2dFLyJUhAKJ4xlzeGVYK3qlVHH4ulzccbSbu/7ltZSq3Nu6qS4LZkwDnNmjT66bn6johxM9+q996CJ+Ze3cvI+pIhxITFU81qib5J2xvn6LlFJTwNcVvVt1e6v0Ebd1MxKlujyYMcVA5jj6ZNJXlwWpKQtyoneYuLEfAP7Ry5aOWZmnK/dU9PlMgVCpwyuVUpPk66DPNjQxUdE7Pfr0it4Yw989d5A9rb0pk5q55tWVO0EPY0xrM+YxuXfljlXRX7W6kQ+/YzGzq/Lr/yulVC7nXF8g2aOPsrihkuq01ogB/vZnbzESjWX06MGeG2c4GsNkWZePCs9vEGNV9OsW1vL1X5/2m4qVUj7gu4q+fySaGDcfi5uM9d6grw4HU4IX7EcKxo3dwknv0YMd7rnW5cMb7mNV9EopVSy+S5rffWwnv/eDnUDqhVW3jTMc9bRuyoOEgxZhzxz0MWefuDEpk5q5LLFDPtu6fFSkBL3235VSZ5/vgv54zxBvOXPEe4O+ocq+MWpkNEYsbhiIxBJDK73zycSdKeuNsT9Oz3JLxPkhwOSDfoxx9EopVSy+S5qBkShtzvBHb+cmEfTReGKSs5pyO+i9M0RGnaS3Wzgmow9viRCPZ95MlS9vq0hbN0qpqeC7pBkYiRKJxjk1EEnp0ddVhBCxe/RuD78qS0Xv7mP34cnSo7fbO6bAit7t0YeDVkEXc5VSaqJ8F/TuPPNtPanTFFSGA5QHAwyPxhITmrmtm9SKPtmjN2Tr0YunRz/x43NbN+VazSulpoiv0iYaizPiXGxt6xlOuVGqMhygPGQxPBpPTFFc7bRuvNMgxJ2gNzn68AFLnFE5mW2dfFQ4E5uNNUWxUkoVk6+CfsAzeVl771BK66ayLEh5KLWir0lU9MnQjXpaN9n68CJOtZ+lrZOPREWvF2KVUlPEV2njnXc+vXVTFQ5QFrQYjsaz9OiTFX0s7h1emVnRWyKJcfaFVPRuj16HViqlpop/g96Zjwbg41cs46OXLU1U9InWjRPws6uSc9JHUy7GZlb07jj6Qm+Yckfd6IgbpdRU8VXauBdiRaC9ZygxJv4jTUs4b241ZaEAI9F4snXj9Ojvfs95fPPWjUCyR+8Or8xe0U/+hqmxpj9QSqli8lXQD4zYPfqlDZW09SQrejePy4OW3aNPa93UV4VZPbcGSB11Yz9hKvVrSGIc/eRumNKKXik1VfJKGxHZIiIHRKRZRO7Nsr5eRJ4Qkd0i8qqIrM9332JyA3xhXQX9I9FE0AectC4PBRhxgr4saBHyTH1gOR8mp0DIPrLGkuT0CIUMgy/X1o1SaoqNmzYiEgDuB24A1gG3ici6tM3+GNhpjLkY+ATwzQnsWzRuj762Ikgsnrwz1q283eGV/SPRRNvG5W4Ti9n9HvfBIukVvT2OHmf2yokfo7ZulFJTLZ+ychPQbIw5ZIyJAI8BN6dtsw54DsAY8yawXETm5blv0bhTG9SWh4gZkxhB44Z1ecieYtidi97LzeyY88Mh56Rmlntn7OR69FrRK6WmSj5pswho8bxudZZ57QI+CCAim4BlwOI89y2a/kRFH0pcTAWw3NaNe2es83QpL7dFE3PnujHZ+/Ay2UnNwlrRK6WmVj5Bny3N0id6/ypQLyI7gd8BXgeiee5rfxGRO0Vku4hs7+zszOOwMg2MRAlY9gO43ZuaIBnIFeEAg5HsFb1b9adcjM3Shw84rZuCJzXTil4pNcXyecJUK7DE83ox0ObdwBjTB9wBIHZpfNj5Uznevp7P8SDwIEBTU1PWHwbjGRiJURUOYDnTFLitm4CTyHOqw5wZjnJqYIQVc6pS9k326N0pEMj6FCn3Ymyhk5olxtFrRa+UmiL5lJXbgNUiskJEwsCtwJPeDURklrMO4NPAC074j7tvMQ2MRKkqCyaC3Z1y2M3jebXlABw9NZjZo3e2yXzwSOrXSB1HP/Fj1EnNlFJTbdyK3hgTFZF7gKeBAPCQMWafiNzlrH8AWAv8s4jEgP3Ap8ba9+ycin0xtqosiDtqcjSW2qOfX2cHfTRuMnr0iYo+nh70WXr0znz0hV6MXbegljULaie8r1JKFSKvh4MbY7YCW9OWPeD5+L+B1fnue7b0j8SoKgsmgj3qDJV0K3y3ogeoLgul7CsZPfpcT5hKzmxZyFw3liVs/cxVE95PKaUK5av+wcBIlOqyQKLSjqYNr0wN+tQeeUZFn9g3+6RmxpisV5qVUmqm8V3QV4WTPfqIU9G7FX5teTDRI8/Zo89o3aR+DcvyXIz11XdPKeVXvoqq/hF72GSydZNalYtIok9fXZ7ausns0Wfvw4tMblIzpZSaar4K+uSoG/t1eo8eYF5tGZC7ok88HDxHH94eXln4fPRKKTXV/BX0kdSLsaNOdS6es5zv9Okzb5hyK3r7tck5H/3khlcqpdRUy2vUTal444tbiMUNP9xuz7rgVvRWSkXvtm6yz3UTT+nRZ5/ULB4v/IYppZSaar4K+oAliT+QHEcfyBb0OSr69CkQso26MYn+/dk5D6WUKiZfBb3LDfbRWOqdsQC/unYe+9v7WNpQmbJPsnXjmdQsni3ovfPgaNIrpWY+XwZ94sKqW9F7Su+lsyv5+q9vyNzH6eO7Fb0xBkOWG6Ysz8PBi37kSilVfL66GOtKtG7imT36XBI9es8TprL14cWp6NEevVKqRPg66JPj6MffJ9Gjj40/qVmiR+/L755Sym98GVWWp0cvkt9492xTIGS/GJv7Qq1SSs1Evg76aJaLqblkndTMkNGIt0SITWJSM6WUmmq+DHp3muJoLJ4ytHIs7mbJHn3258KKDq9USpUYXwZ9snWT/+P+Mnv05Lhhyv47NoHfFpRSajr5MuiTN0zFU4ZWjiW9R29y9OEDnu005pVSpcCXQV9Ijz75cPDkpGZZnxlrJT+39uiVUqXAn0HvecJUvn10N7Sdzk2isk/fP9HLj2uPXilVGnwZ9MkHj5hE6OdDJDmpWTLoM+e6gYn9tqCUUtPJl0FveUbdTCSMLZHE8Er37/S9Uy7G+vK7p5TyG19GVaFVtyXJSc0SFb2Vq6KPa49eKVUSfBn03lE3E+mjC5II+ERFn9GjTw7D1NaNUqoU5BX0IrJFRA6ISLOI3JtlfZ2I/KuI7BKRfSJyh2fdERHZIyI7RWR7MQ8+F++Y+HyHV4Id6omgz/LQEvu1/XdUL8YqpUrEuNMUi0gAuB+4FmgFtonIk8aY/Z7N7gb2G2NuFJFG4ICIPGKMiTjr32OM6Sr2wefirejLQ4G898vWo882qRnoOHqlVOnIp6LfBDQbYw45wf0YcHPaNgaoEbuvUQ10A9GiHukEeKvuiXRXLEmd1Mxelr2i1ztjlVKlIp+gXwS0eF63Osu8vgWsBdqAPcBnjDHOY7YxwDMiskNE7pzk8eYl2brJ/85YsPvvmT36zLluwKnoNeiVUiUgn6DPlmYm7fX1wE5gIbAR+JaI1Drr3mmMuRS4AbhbRK7O+kVE7hSR7SKyvbOzM59jz8n7zNiJVN3eHn2uG6YSc93HJ3ahVymlpks+Qd8KLPG8XoxduXvdATxubM3AYWANgDGmzfm7A3gCuxWUwRjzoDGmyRjT1NjYOLGzSON9wtREwngi4+jj+oQppVSJyCfotwGrRWSFiISBW4En07Y5BrwXQETmARcAh0SkSkRqnOVVwHXA3mIdfC5uGGd7FOB4+7mVfGKZlb11Y68r/BiVUmqqjDvqxhgTFZF7gKeBAPCQMWafiNzlrH8A+BLwsIjswS6C/9AY0yUiK4EnnHAMAo8aY546S+eS4A33iffo4xnLcn1u7dErpUrBuEEPYIzZCmxNW/aA5+M27Go9fb9DwIZJHuOEecN9ImGctaLPMR99tnVKKTUT+bL54K26J3RnrPOYwFyfK/216Eh6pVQJ8GfQW4W1bvKp6EUreqVUifFl0AcK7KNnq9C1R6+UKnW+DHrvaJjABO+MzVyWO+h1eKVSqhT4MugDBYZxtgo91zj69I+VUmqm8mfQexJ4Ik+YyjYuPn2ZVeDnVkqp6eLLoJdCR91k6dGPOepGc14pVQJ8GfQpFf0Ex9Gny7wY61mnwyuVUiXAn0Ff4J2x2X4o5JqPPts6pZSaiXwZ9N6++oSGV+Yx6iZ1HL0mvVJq5vNn0Hsr+gneGZv5uXJ/bq3olVKlwJdBX+jwyuzBrTdMKaVKmy+DvtAhkPn16MfeXimlZhpfBj0kL8JOdFKzdJk9em3dKKVKi2+D3g3hCd0Zm+3zpN8w5a3oNemVUiXAx0HvVPSTvDM2vcqfyHBNpZSaCXwb9MnWzWR79GO1bjT0lVIzn3+D3gnh4g+vzL1OKaVmIt8GvRSrR6/TFCulSpxvg95t3Uz0mbHpMqcp1knNlFKlxfdBH5jAGWar0NN/UOgUCEqpUuPboE+Mupn0xdjc22iPXilVCvIKehHZIiIHRKRZRO7Nsr5ORP5VRHaJyD4RuSPffc+WQoZXZmvSp+/vHYKp4+iVUqVg3KAXkQBwP3ADsA64TUTWpW12N7DfGLMBeDfwDREJ57nvWVHInbHZnxmb/trToy/kwJRSaorlU9FvApqNMYeMMRHgMeDmtG0MUCN2Q7sa6Aaiee57VriVd2CSrZsxHzyiPXqlVAnIJ+gXAS2e163OMq9vAWuBNmAP8BljTDzPfc8KN+AnNupmYo8S1IuxSqlSkE/QZ0szk/b6emAnsBDYCHxLRGrz3Nf+IiJ3ish2Edne2dmZx2GNrZCLsdkfPJL982Zbp5RSM1E+Qd8KLPG8XoxduXvdATxubM3AYWBNnvsCYIx50BjTZIxpamxszPf4c7IKGF6ZrfpPfy6sVvRKqVKTTwxuA1aLyAoRCQO3Ak+mbXMMeC+AiMwDLgAO5bnvWREoaHhl5rL03UVyr1NKqZkoON4GxpioiNwDPA0EgIeMMftE5C5n/QPAl4CHRWQPdrvmD40xXQDZ9j07p5LKregn/+CR9OGVWtErpUrLuEEPYIzZCmxNW/aA5+M24Lp8950Kyfno899novPRa84rpUqBb++MTUyBMKGLsTrqRinlP74Nequg4ZXjL9MevVKq1Pg26Iv14JHMG6a0oldKlRbfBr1biU9seGWWZRmfV4NeKVVafBz0Z+fO2EBK0Bd4cEopNYV8G/TJ+egne2ds2nz0nu+YznWjlCoFvg/6ic1ema1Hn3sbreiVUqXAt0HvVtuTnusmfT56nb1SKVVifBv0gQIeDq5PmFJK+ZF/g76A1k1ePXp9ZqxSqsT4NujdEJ7IxdiJ9ug155VSpcC3Qe8G/ET66Nm21GmKlVKlzrdBP5mK3kppz6Rvk7m9UkrNZP4N+kKGVzrfjaDndtrMHr1ejFVKlRbfBr076mZCrRtn2+A4c84X0hZSSqnp4tugtwqZptj529vukSzfISvxQ6TQo1NKqanj36B3++0TOEMrz4q+kJuxlFJquvg26CfzzNiAZWUsy7ad9uiVUqXAt0GfvBhb/B59ITNjKqXUdPFt0LsDZwqZvXK8fbINw1RKqZnKt0FfSBgnevSB8Xr0udcppdRM4/ugL+SZsYGU1k3uz61Br5QqBXkFvYhsEZEDItIsIvdmWf95Ednp/NkrIjERaXDWHRGRPc667cU+gVwCBQyvzHfUjQ6vVEqVkuB4G4hIALgfuBZoBbaJyJPGmP3uNsaY+4D7nO1vBH7PGNPt+TTvMcZ0FfXIx5GYvXIiv7NkacmMNaOlBr1SqhTkE4ObgGZjzCFjTAR4DLh5jO1vA75fjIObjEL66Ok9epHsrZ9CRvQopdR0ySfoFwEtntetzrIMIlIJbAF+7FlsgGdEZIeI3FnogU7UZMbRB51fA3LtaxXwQ0QppabLuK0bss/ea3JseyPwUlrb5p3GmDYRmQs8KyJvGmNeyPgi9g+BOwGWLl2ax2GNrZCHg6f36HPtqcMrlVKlJJ+KvhVY4nm9GGjLse2tpLVtjDFtzt8dwBPYraAMxpgHjTFNxpimxsbGPA5rbIX00dPnusld0esNU0qp0pFP0G8DVovIChEJY4f5k+kbiUgdcA3wU8+yKhGpcT8GrgP2FuPAx1PIEEjJ0qPPvp37NQo/PqWUmirjtm6MMVERuQd4GggADxlj9onIXc76B5xNbwGeMcYMeHafBzzhBGgQeNQY81QxTyCXQu6MTT6sZLwevV6MVUqVjnx69BhjtgJb05Y9kPb6YeDhtGWHgA2TOsICFfTgkcTF2LH31XH0SqlS4ts7YwsZdZM+141W9EopP/Bt0E+qR2/l16PXnFdKlQL/Bv0khlcm76rVil4pVfp8G/SBAqru9B59rl3Ha+0opdRM4t+gL+jBI+6+Y4+6ST5KcBIHqJRSU8S3QS9SeOsm2aMfewoEvWFKKVUKfBv0gQKGVyYqdcuu7nMPr9SKXilVOvwb9JOY1ExEsJw/422nlFIznW+DvqCHg7v7SvJP1u20oldKlRDfBv3mVbP5aNMSFtVX5L2P94eDOH+ybqcVvVKqhOQ1BUIpWjSrgq99+OIJ7SOedo8luZ9OpT16pVQp8W1FXwjvHDaWCJJjJL3eMKWUKiUa9B5usFuJi7E5ttMnTCmlSogGvUfyEYHJqj6bwDhz4Sil1EyiQe9hSWpFnyvIC3l6lVJKTRcNeg/xjKaxxqjotXWjlColGvQe3vHxY98wpRdjlVKlQ4Pew/JU6pY1Vusm9W+llJrJNOg9rJSKfvwnTOkNU0qpUqBB75HI7XEuxsoYQy+VUmqm0aD3yL9Hr/15pVTp0KD38Pbox5umWINeKVUq8gp6EdkiIgdEpFlE7s2y/vMistP5s1dEYiLSkM++M4mVVtHnnNTMIvdzBpVSaoYZN+hFJADcD9wArANuE5F13m2MMfcZYzYaYzYCfwT8whjTnc++M0nqfPTjVfRTd1xKKTUZ+VT0m4BmY8whY0wEeAy4eYztbwO+X+C+0yx9rpvco260daOUKhX5BP0ioMXzutVZlkFEKoEtwI8nuu9MkO9cN3oxVilVSvIJ+myJZnJseyPwkjGme6L7isidIrJdRLZ3dnbmcVjFlz7XTa4+/FhDL5VSaqbJJ+hbgSWe14uBthzb3kqybTOhfY0xDxpjmowxTY2NjXkcVvG5DxoRGbsPL9q6UUqVkHyCfhuwWkRWiEgYO8yfTN9IROqAa4CfTnTfmSJlPnprvHH0U3lkSilVuHEfJWiMiYrIPcDTQAB4yBizT0TuctY/4Gx6C/CMMWZgvH2LfRLFIp4e/XhTIGhFr5QqFXk9M9YYsxXYmrbsgbTXDwMP57PvTJXo0VvjzEdv6Vz0SqnS4duHgxfCO1lZwJLEk6TS/cqaecyqDE/loSmlVME06D0SDx4BPn/9BZSHsl/CuHbdPK5dN2/qDkwppSZBg97D++Sod543Z3oPRimlikQnNfPwznWjlFJ+oUHvoY8IVEr5kQa9R/Lh4NN7HEopVUwa9B7e+eiVUsovNOg9Ek+Y0u+KUspHNNI8tEevlPIjDXqP5LPBNeiVUv6hQe+hwyuVUn6kQe8hejFWKeVDGvQeWtErpfxIg95j9bxq7rpmFZtX6vQHSin/0LluPEIBi3tvWDPdh6GUUkWlFb1SSvmcBr1SSvmcBr1SSvmcBr1SSvmcBr1SSvmcBr1SSvmcBr1SSvmcBr1SSvmcGGOm+xgyiEgncLTA3ecAXUU8nJlOz9ffzqXzPZfOFYp/vsuMMY3ZVszIoJ8MEdlujGma7uOYKnq+/nYune+5dK4wteerrRullPI5DXqllPI5Pwb9g9N9AFNMz9ffzqXzPZfOFabwfH3Xo1dKKZXKjxW9UkopD98EvYhsEZEDItIsIvdO9/GcDSJyRET2iMhOEdnuLGsQkWdF5KDzd/10H2ehROQhEekQkb2eZTnPT0T+yHm/D4jI9dNz1IXLcb5fEJHjznu8U0Te51lX6ue7RESeF5E3RGSfiHzGWe7L93iM853699gYU/J/gADwNrASCAO7gHXTfVxn4TyPAHPSlv0VcK/z8b3A16b7OCdxflcDlwJ7xzs/YJ3zPpcBK5z3PzDd51CE8/0C8PtZtvXD+S4ALnU+rgHecs7Ll+/xGOc75e+xXyr6TUCzMeaQMSYCPAbcPM3HNFVuBr7rfPxd4Nem71AmxxjzAtCdtjjX+d0MPGaMGTHGHAaasf8dlIwc55uLH8633RjzmvPxGeANYBE+fY/HON9cztr5+iXoFwEtntetjP0NLVUGeEZEdojInc6yecaYdrD/YQFzp+3ozo5c5+fn9/weEdnttHbcNoavzldElgOXAK9wDrzHaecLU/we+yXoJcsyPw4neqcx5lLgBuBuEbl6ug9oGvn1Pf8HYBWwEWgHvuEs9835ikg18GPgd40xfWNtmmVZyZ1zlvOd8vfYL0HfCizxvF4MtE3TsZw1xpg25+8O4AnsX+tOisgCAOfvjuk7wrMi1/n58j03xpw0xsSMMXHg2yR/dffF+YpICDv0HjHGPO4s9u17nO18p+M99kvQbwNWi8gKEQkDtwJPTvMxFZWIVIlIjfsxcB2wF/s8b3c2ux346fQc4VmT6/yeBG4VkTIRWQGsBl6dhuMrKjfwHLdgv8fgg/MVEQH+EXjDGPPXnlW+fI9zne+0vMfTfWW6iFe434d9Vftt4E+m+3jOwvmtxL4ivwvY554jMBt4Djjo/N0w3cc6iXP8PvavsqPY1c2nxjo/4E+c9/sAcMN0H3+Rzvd7wB5gt/Mff4GPzvdd2K2I3cBO58/7/Poej3G+U/4e652xSinlc35p3SillMpBg14ppXxOg14ppXxOg14ppXxOg14ppXxOg14ppXxOg14ppXxOg14ppXzu/wNkk6EzaLLqWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'SingleStop',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .0001, Epochs = 45, Batch_size = 1,\n",
    "                              Regeneration = 4, FractionDrop = 0.0, \n",
    "                              batchSz2 = 1, ep2 = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65726233-9894-471e-8dfe-0ebd898601f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "SingleStop Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.0001 \t Epochs -> 45 \t Batch size -> 1\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "Average Accuracy: [0.88928966 0.91939639 0.93801987 0.94409274 0.95366212 0.95594404\n",
      " 0.96002944 0.96113361 0.96201693 0.96540302 0.96566066]\n",
      "Median Accuracy: [0.88903201 0.91866028 0.93761501 0.94423994 0.95362532 0.95620167\n",
      " 0.9598822  0.96117041 0.96153846 0.96595511 0.96577108]\n",
      "Accuracy Deviation: [0.00662045 0.00508393 0.00321368 0.00275647 0.0014855  0.00202295\n",
      " 0.00186368 0.00148321 0.00211942 0.00220217 0.00174233]\n",
      "Training Latency: [ 3.43524373  6.72127223 13.19147611 20.01296318 27.14920032 33.29252231\n",
      " 39.27167797 45.81688166 52.22197831 59.19540393 65.87207437]\n",
      "CPU Usage(%): [1.33333333 1.25       1.41666667 0.91666667 1.625      2.5\n",
      " 1.08333333 0.625      0.66666667 0.54166667 1.79166667]\n",
      "Memory Usage(KiB): [1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'SingleStop',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .0001, Epochs = 45, Batch_size = 1,\n",
    "                              Regeneration = 1, FractionDrop = 0.0, \n",
    "                              batchSz2 = 1, ep2 = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eccaf7e-0dca-4868-bc10-bbb29ba098bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU i9-12900K that has 24 cores\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "SingleStop Report:\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 2048\n",
      "Learning Rate -> 0.0001 \t Epochs -> 80 \t Batch size -> 1\n",
      "\n",
      "Data Usage Ratio: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "Average Accuracy: [0.88612441 0.91601031 0.93669488 0.94501288 0.95373574 0.95656974\n",
      " 0.96061833 0.96212734 0.96415163 0.96396762 0.96532941]\n",
      "Median Accuracy: [0.88553551 0.9144277  0.93632683 0.94497606 0.9528892  0.9563857\n",
      " 0.96080235 0.96209055 0.96429884 0.9646669  0.96577108]\n",
      "Accuracy Deviation: [0.00658228 0.00561037 0.00197517 0.00166398 0.00242496 0.00104102\n",
      " 0.00222055 0.00322314 0.00193499 0.00188715 0.00223756]\n",
      "Training Latency: [  5.66448963  11.15347946  22.06845915  33.1299392   44.16678667\n",
      "  56.11718166  66.53482747  76.74035966  89.44718266 100.42856669\n",
      " 111.30929673]\n",
      "CPU Usage(%): [0.91666667 0.75       0.66666667 0.58333333 1.         0.95833333\n",
      " 1.45833333 0.5        0.58333333 0.83333333 1.33333333]\n",
      "Memory Usage(KiB): [1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469 1449.51855469 1449.51855469 1449.51855469 1449.51855469\n",
      " 1449.51855469]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Results = DataRatio_Evaluator(x_train, x_test, y_train, y_test, ratio_list = Ratio_list, \n",
    "                              HDC = True, repetitions = 10, model_select = 'SingleStop',                \n",
    "                              Classes = 9, Features = 257, Dimensions = 2048,\n",
    "                              Learning_rate = .0001, Epochs = 80 , Batch_size = 1,\n",
    "                              Regeneration = 1, FractionDrop = 0.0, \n",
    "                              batchSz2 = 1, ep2 = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995af01-ea7d-4a75-8cb7-a46e50398c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f5abc-d8ae-4c51-9c37-fd180e4e61c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7a40a-5cb3-4916-ac77-8e1b9bb458c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryAccuracy(y, ypred, train_or_test = 'training', report = False):\n",
    "    if type(y) == np.ndarray and type(ypred) == np.ndarray:\n",
    "        y = torch.from_numpy(y)\n",
    "        ypred = torch.from_numpy(ypred)\n",
    "        \n",
    "    lst = torch.eq(y, ypred)\n",
    "    count = 0\n",
    "    for i in lst:\n",
    "        if i == True:\n",
    "            count += 1\n",
    "    accuracy = count/len(lst) * 100\n",
    "    \n",
    "    if report == True:\n",
    "        print(f'The {train_or_test} accuracy is about: {round(accuracy, 2)}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e208efa0-a085-41f7-a840-590d7224aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                    repeat_times = 1, model_select = None, verbose = True,\n",
    "                    Classes = 9, Features = 257, Dimensions = 1024,\n",
    "                    Learning_rate = 0.02, Epochs = 64, Batch_size = 64,\n",
    "                    Regeneration = 5, FractionDrop = 0.1):\n",
    "    \n",
    "    if (model_select == 'OnlineHD') or (model_select == 'NeuralHD'):\n",
    "        # For the training set\n",
    "        x_train = torch.from_numpy(x_train)\n",
    "        y_train = torch.from_numpy(y_train)\n",
    "        # For the testing set\n",
    "        x_test = torch.from_numpy(x_test)\n",
    "        y_test = torch.from_numpy(y_test)\n",
    "        \n",
    "    # Lists for storing accuracy scores(%) and time measurements(in seconds)\n",
    "    Tr_lst = np.zeros((repeat_times, ))\n",
    "    Te_lst = np.zeros((repeat_times, ))\n",
    "    \n",
    "    Tr_latency_lst = np.zeros((repeat_times, ))\n",
    "    Inference_time_lst = np.zeros((repeat_times, ))\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Training on 12th Gen Intel Core i9-12900K')\n",
    "    \n",
    "    for each_time in tqdm(range(repeat_times)): \n",
    "        # here is why time on loading display is larger than real runtime \n",
    "        time.sleep(2)\n",
    "        # set up training latency and inference time\n",
    "        training_start = 0.0\n",
    "        training_end = 0.0\n",
    "        infer_start = 0.0\n",
    "        infer_end = 0.0\n",
    "        \n",
    "        \n",
    "        if model_select == 'NeuralHD':\n",
    "            model = NeuralHD(classes = Classes, \n",
    "                             features = Features, \n",
    "                             dim = Dimensions, \n",
    "                             batch_size = Batch_size,\n",
    "                             trainopt = 3,\n",
    "                             bestinclass = True)\n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, x_test, y_train, y_test, \n",
    "                      epochs = Epochs, \n",
    "                      regenloops = Regeneration, \n",
    "                      fractionToDrop = FractionDrop)\n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "        \n",
    "        \n",
    "        if model_select == 'OnlineHD':\n",
    "            model = OnlineHD(classes = Classes, \n",
    "                             features = Features, \n",
    "                             dim = Dimensions)\n",
    "\n",
    "            # Optional: For both training and testing sets, check if gpu/cuda is available to use\n",
    "            '''\n",
    "            if torch.cuda.is_available() and model_select == 'OnlineHD':\n",
    "                print(f'Training on {torch.cuda.get_device_name(0)}\\n')\n",
    "                model = model.to('cuda')\n",
    "                x_train = x_train.to('cuda')\n",
    "                y_train = y_train.to('cuda')\n",
    "                x_test = x_test.to('cuda')\n",
    "                y_test = y_test.to('cuda')\n",
    "            '''\n",
    "            \n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, y_train, \n",
    "                      encoded = False, \n",
    "                      lr = Learning_rate, \n",
    "                      epochs = Epochs, \n",
    "                      batch_size = Batch_size, \n",
    "                      one_pass_fit = False)\n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "            \n",
    "            \n",
    "        if model_select == 'MLP':\n",
    "            model = MLP(classes = Classes,\n",
    "                        features = Features,\n",
    "                        dim = Dimensions)\n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, y_train,  \n",
    "                      epochs = Epochs,\n",
    "                      batch_size = Batch_size,\n",
    "                      lr = Learning_rate)\n",
    "            \n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "        \n",
    "        \n",
    "        if model_select == 'SVM':\n",
    "            model = SVM()\n",
    "            \n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, y_train)\n",
    "            \n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()        \n",
    "        \n",
    "        training_latency_sec = training_end - training_start\n",
    "        Tr_latency_lst[each_time] = training_latency_sec\n",
    "        \n",
    "        # start inference time\n",
    "        infer_start = time.time()  \n",
    "        \n",
    "        # prediction\n",
    "        ypred = model(x_train)\n",
    "        \n",
    "        # prediction completed\n",
    "        infer_end = time.time()\n",
    "        inference_time_sec = infer_end - infer_start\n",
    "        Inference_time_lst[each_time] = inference_time_sec\n",
    "        \n",
    "        Tr_accuracy = binaryAccuracy(y_train, ypred, \n",
    "                                     train_or_test = 'training', \n",
    "                                     report = False)\n",
    "        Tr_lst[each_time] = Tr_accuracy\n",
    "        \n",
    "        # prediction\n",
    "        ypred = model(x_test)\n",
    "        Te_accuracy = binaryAccuracy(y_test, ypred, \n",
    "                                     train_or_test = 'testing', \n",
    "                                     report = False)\n",
    "        Te_lst[each_time] = Te_accuracy\n",
    "        \n",
    "    # For the training set\n",
    "    # Tr_max = max(Tr_lst)\n",
    "    Tr_mean = np.mean(Tr_lst)\n",
    "    Tr_variance = np.var(Tr_lst)\n",
    "    \n",
    "    # For the testing set\n",
    "    # Te_max = max(Te_lst)\n",
    "    Te_mean = np.mean(Te_lst)\n",
    "    Te_variance = np.var(Te_lst)\n",
    "    \n",
    "    # For training latency and inference time\n",
    "    avg_training_latency = np.mean(Tr_latency_lst)\n",
    "    avg_inference_time = np.mean(Inference_time_lst)\n",
    "    \n",
    "    # The report\n",
    "    if verbose == True:\n",
    "        print(f'The applied model is {model_select}, and its hyper-parameters are set as:\\n')\n",
    "        print(f'Classes -> {Classes} \\t Features -> {Features} \\t Dimensions -> {Dimensions}')\n",
    "        print(f'Learning Rate -> {Learning_rate} \\t Epochs -> {Epochs} \\t Batch size -> {Batch_size}\\n')\n",
    "    \n",
    "    if (verbose == True) and (model_select == 'NeuralHD'):\n",
    "        print(f'Regeneration -> {Regeneration} \\t FractionDrop -> {FractionDrop}\\n')\n",
    "        \n",
    "    if (repeat_times > 1) and (verbose == True):\n",
    "        print(f'***** For {repeat_times} times of iteration *****\\n') \n",
    "        print(f'The variance on the training set: {round(Tr_variance, 4)}\\nThe variance on the testing set: {round(Te_variance, 4)}')   \n",
    "    \n",
    "    if verbose == True:        \n",
    "        print(f'The average accuracy on the training set: {round(Tr_mean, 4)}\\nThe average accuracy on the testing set: {round(Te_mean, 4)}')\n",
    "        print(f'The average training latency: {round(avg_training_latency, 4)} seconds\\nThe average inference time: {round(avg_inference_time, 4)} seconds\\n')\n",
    "    return [Tr_mean, Tr_variance, Te_mean, Te_variance, avg_training_latency, avg_inference_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b666872-93ab-4806-a7d3-ac89374b5eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine-tuning all hyperparamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521adad6-1535-4a3f-9b0a-4d88f087e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimentionality: [1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176]\n",
      "Learning rate: [1e-06, 2e-06, 3e-06, 4e-06, 5e-06, 1e-05, 2e-05, 3e-05, 4e-05, 5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
      "Regenerate loops: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Dropping rates: [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
      "Epochs: [25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "# Lists for iterative fine-tuning\n",
    "dim_list = [1024, 1224, 1488, 1888, 2048, 2222, 2488, 2888]\n",
    "\n",
    "print(f'Dimentionality: {dim_list}')\n",
    "\n",
    "lr_list = [0.000001, 0.000002, 0.000003, 0.000004, 0.000005, \n",
    "           0.00001, 0.00002, 0.00003, 0.00004, 0.00005,\n",
    "           0.0001, 0.0002, 0.0003, 0.0004, 0.0005,\n",
    "           0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "print(f'Learning rate: {lr_list}')\n",
    "\n",
    "regenloop = [number for number in range(11,26)]\n",
    "print(f'Regenerate loops: {regenloop}')\n",
    "\n",
    "fractiontoDrop = [0, 0.01, 0.02, 0.03, 0.04, 0.05, \n",
    "                  0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7] \n",
    "print(f'Dropping rates: {fractiontoDrop}')\n",
    "\n",
    "ep_list = [number**2 for number in range(5,11)]\n",
    "print(f'Epochs: {ep_list}')\n",
    "Repeat_times = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec609e1-0f55-4597-8d69-1e448fc80ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_Visualizer(X, Y_lst, hyperParam_name, labels = 'time'):\n",
    "    Y_labels = list()\n",
    "    print('\\nThe Analysis')\n",
    "    if labels == 'acc':\n",
    "        Y_labels = ['Training Accuracy', 'Testing Accuracy', \n",
    "                    'Training Variance', 'Testing Variance']\n",
    "        Tr_lst = Y_lst[0]\n",
    "        Te_lst = Y_lst[1]\n",
    "        Tr_var = Y_lst[2]\n",
    "        Te_var = Y_lst[3]\n",
    "        print(f'List of training accuracy: {Tr_lst}\\n List of training variance: {Tr_var}\\n List of testing variance: {Te_var}\\n List of testing accuracy{Te_lst}\\n')\n",
    "        fig, axs = plt.subplots(2, 1, figsize = (11, 15))\n",
    "        axs = np.atleast_2d(axs)\n",
    "        axs[0, 0].set_title(f'Accuracy in {hyperParam_name}')\n",
    "        axs[0, 0].plot(X, Tr_lst, lw = 2, color='blue', alpha=0.95, label = Y_labels[0])\n",
    "        axs[0, 0].plot(X, Te_lst, lw = 2, color='red', alpha=0.95, label = Y_labels[1])\n",
    "        xtr_max = X[np.argmax(Tr_lst)]\n",
    "        ytr_max = Tr_lst.max()\n",
    "        axs[0, 0].plot(xtr_max, ytr_max, marker=\"o\", markersize=7, markeredgecolor='green', markerfacecolor='blue')\n",
    "        xte_max = X[np.argmax(Te_lst)]\n",
    "        yte_max = Te_lst.max()\n",
    "        axs[0, 0].plot(xte_max, yte_max, marker=\"o\", markersize=7, markeredgecolor='green', markerfacecolor='red')\n",
    "        axs[0, 0].set(xlabel = hyperParam_name, ylabel = 'Accuracy(%)')\n",
    "        axs[0, 0].legend(fontsize = 9, loc = 1)\n",
    "        print(f'{hyperParam_name} at {xtr_max} got maximum training accuracy -> {ytr_max}')\n",
    "        print(f'{hyperParam_name} at {xte_max} got maximum testing accuracy -> {yte_max}')\n",
    "        \n",
    "        axs[0, 1].set_title(f'Variance in {hyperParam_name}')\n",
    "        axs[0, 1].plot(X, Tr_var, lw = 2, color='blue', alpha=0.95, label = Y_labels[2])\n",
    "        axs[0, 1].plot(X, Te_var, lw = 2, color='red', alpha=0.95, label = Y_labels[3])\n",
    "        xtr_min = X[np.argmin(Tr_var)]\n",
    "        ytr_min = Tr_var.min()\n",
    "        axs[0, 1].plot(xtr_min, ytr_min, marker=\"o\", markersize=7, markeredgecolor='green', markerfacecolor='blue')\n",
    "        xte_min = X[np.argmin(Te_var)]\n",
    "        yte_min = Te_var.min()\n",
    "        axs[0, 1].plot(xte_min, yte_min, marker=\"o\", markersize=7, markeredgecolor='green', markerfacecolor='red')\n",
    "        axs[0, 1].set(xlabel = hyperParam_name, ylabel = 'Variance')\n",
    "        axs[0, 1].legend(fontsize = 9, loc = 1)     \n",
    "        print(f'{hyperParam_name} at {xtr_min} got minimum training variance -> {ytr_min}')\n",
    "        print(f'{hyperParam_name} at {xte_min} got minimum testing variance -> {yte_min}')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        Y_labels = ['Training Latency', 'Inference Time']\n",
    "        Tr_latency_lst = Y_lst[0]\n",
    "        Inference_time_lst = Y_lst[1] \n",
    "        print(f'List of Training Latency: {Tr_latency_lst}\\n List of Inference Time: {Inference_time_lst}\\n')\n",
    "        fig, axs = plt.subplots(2, 1, figsize = (11, 15))\n",
    "        axs = np.atleast_2d(axs)        \n",
    "        axs[0, 0].set_title(f'Training Latency in {hyperParam_name}')\n",
    "        axs[0, 0].plot(X, Tr_latency_lst, lw = 2, color='blue', alpha=0.95, label = 'Training Latency')\n",
    "        axs[0, 0].set(xlabel = hyperParam_name, ylabel = 'Time(seconds)')\n",
    "        axs[0, 0].legend(fontsize = 9, loc = 1)\n",
    "        \n",
    "        axs[0, 1].set_title(f'Inference Time in {hyperParam_name}') \n",
    "        axs[0, 1].plot(X, Inference_time_lst, lw = 2, color='red', alpha=0.95, label = 'Inference Time')\n",
    "        axs[0, 1].set(xlabel = hyperParam_name, ylabel = 'Time(seconds)')\n",
    "        axs[0, 1].legend(fontsize = 9, loc = 1)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3fa1b-3dd3-4a48-a4d4-5f33f5fc72d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OnlineHD model fine-tuning\n",
    "Keep the batch size at **64**, varying the dimentionality, learning rate, and finally the epochs.\n",
    "    \n",
    "    dim_list = [512, 1024, 2048, 4096, \n",
    "                8192, 16384, 32768, 65536] -> 16384\n",
    "    \n",
    "    lr_list = [0.01, 0.02, 0.03, 0.04, 0.05,\n",
    "               0.001, 0.002, 0.003, 0.004, 0.005, \n",
    "               0.0001, 0.0002, 0.0003, 0.0004, 0.0005, \n",
    "               0.00001, 0.00002, 0.00003, 0.00004, 0.00005] -> 0.00001\n",
    "               \n",
    "    ep_list = [4, 9, 16, 25, 36, \n",
    "               49, 64, 81, 100, 121] -> 64\n",
    "               \n",
    "    Training on 12th Gen Intel Core i9-12900K\n",
    "    100%|██████████| 20/20 [05:11<00:00, 15.58s/it]\n",
    "    The applied model is OnlineHD, and its hyper-parameters are set as:\n",
    "\n",
    "    Classes -> 9 \t Features -> 257 \t Dimensions -> 16384\n",
    "    Learning Rate -> 1e-05 \t Epochs -> 64 \t Batch size -> 64\n",
    "\n",
    "    ***** For 20 times of iteration *****\n",
    "\n",
    "    The variance on the training set: 0.3912\n",
    "    The variance on the testing set: 0.4178\n",
    "    The average accuracy on the training set: 96.6176\n",
    "    The average accuracy on the testing set: 95.0221\n",
    "    The average training latency: 13.1704 seconds\n",
    "    The average inference time: 0.2481 seconds       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5b9f8f-2c94-4f98-9639-d92b621cf94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:25<00:00,  7.27s/it]\n",
      "100%|██████████| 20/20 [02:28<00:00,  7.44s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.25s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.34s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.32s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:20<00:00,  7.02s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.07s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.07s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.05s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.07s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.17s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.11s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.05s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.11s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.15s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.10s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.11s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.10s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.15s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.15s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.09s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.08s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.15s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.10s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.26s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.11s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.17s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.27s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.25s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.37s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.39s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.37s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.30s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.37s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.38s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.25s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.28s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:21<00:00,  7.06s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.11s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.26s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.17s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.17s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.27s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.16s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.29s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.26s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.25s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.27s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.13s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.37s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.30s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.18s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.15s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.30s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.32s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.28s/it]\n",
      "100%|██████████| 20/20 [02:22<00:00,  7.12s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.22s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.28s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.30s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.30s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.24s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.34s/it]\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.33s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n",
      "100%|██████████| 20/20 [02:23<00:00,  7.20s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.29s/it]\n",
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.46s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:28<00:00,  7.44s/it]\n",
      "100%|██████████| 20/20 [02:28<00:00,  7.45s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:28<00:00,  7.45s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.48s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.48s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.48s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.48s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.25s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.49s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.54s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:34<00:00,  7.72s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.61s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.61s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.48s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.63s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.63s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:33<00:00,  7.68s/it]\n",
      "100%|██████████| 20/20 [02:27<00:00,  7.38s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:33<00:00,  7.65s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.61s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.62s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.64s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.60s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.63s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.61s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.62s/it]\n",
      "100%|██████████| 20/20 [02:33<00:00,  7.67s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.63s/it]\n",
      "100%|██████████| 20/20 [02:33<00:00,  7.70s/it]\n",
      "100%|██████████| 20/20 [02:33<00:00,  7.69s/it]\n",
      "100%|██████████| 20/20 [02:36<00:00,  7.84s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.58s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.57s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.55s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.51s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.59s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:31<00:00,  7.56s/it]\n",
      "100%|██████████| 20/20 [02:28<00:00,  7.45s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.53s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.50s/it]\n",
      "100%|██████████| 20/20 [02:36<00:00,  7.85s/it]\n",
      "100%|██████████| 20/20 [02:37<00:00,  7.88s/it]\n",
      "100%|██████████| 20/20 [02:37<00:00,  7.86s/it]\n",
      "100%|██████████| 20/20 [02:36<00:00,  7.83s/it]\n",
      "100%|██████████| 20/20 [02:38<00:00,  7.93s/it]\n",
      "100%|██████████| 20/20 [02:39<00:00,  8.00s/it]\n",
      "100%|██████████| 20/20 [02:39<00:00,  7.96s/it]\n",
      "100%|██████████| 20/20 [02:34<00:00,  7.72s/it]\n",
      "100%|██████████| 20/20 [02:30<00:00,  7.52s/it]\n",
      "100%|██████████| 20/20 [02:32<00:00,  7.63s/it]\n",
      " 10%|█         | 2/20 [00:21<03:17, 10.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34012/2385594695.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mDimension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     results = HDC_Model_Analyzer(x_train, x_test, y_train, y_test, \n\u001b[0m\u001b[0;32m     20\u001b[0m                                  \u001b[0mrepeat_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRepeat_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_select\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThe_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                  \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34012/2478424569.py\u001b[0m in \u001b[0;36mHDC_Model_Analyzer\u001b[1;34m(x_train, x_test, y_train, y_test, repeat_times, model_select, verbose, Classes, Features, Dimensions, Learning_rate, Epochs, Batch_size, Regeneration, FractionDrop)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtraining_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             model.fit(x_train, y_train, \n\u001b[0m\u001b[0;32m     86\u001b[0m                       \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                       \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\BIASLab_research_project\\MalwareClassification\\OnlineHD_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, encoded, lr, epochs, batch_size, one_pass_fit, bootstrap)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mone_pass_fit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_one_pass_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterative_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\BIASLab_research_project\\MalwareClassification\\OnlineHD_model.py\u001b[0m in \u001b[0;36m_iterative_fit\u001b[1;34m(self, h, y, lr, epochs, batch_size)\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[0mh_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[0mwrong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\BIASLab_research_project\\MalwareClassification\\OnlineHD_model.py\u001b[0m in \u001b[0;36mscores\u001b[1;34m(self, x, encoded)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcos_cdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\BIASLab_research_project\\MalwareClassification\\OnlineHD_model.py\u001b[0m in \u001b[0;36mcos_cdist\u001b[1;34m(x1, x2, eps)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mnorms1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mnorms2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mcdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mcdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setup OnlineHD model's hyper-parameters\n",
    "The_model = 'OnlineHD'\n",
    "Batch_size = 64\n",
    "# Dimension = 1024\n",
    "Learning_rate = 1e-05\n",
    "Epochs = 64\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(dim_list), ))\n",
    "Tr_variance_lst = np.zeros((len(dim_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(dim_list), ))\n",
    "Te_variance_lst = np.zeros((len(dim_list), ))\n",
    "avg_Latency_lst = np.zeros((len(dim_list), ))\n",
    "avg_Inference_lst = np.zeros((len(dim_list), ))\n",
    "\n",
    "\n",
    "for idx in range(0, len(dim_list)):\n",
    "    Dimension = dim_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(dim_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Dimension', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(dim_list, [avg_Latency_lst, avg_Inference_lst], 'Dimension', labels = 'time'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb682805-fc73-4939-8a6b-20159db58ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup OnlineHD model's hyper-parameters\n",
    "The_model = 'OnlineHD'\n",
    "Batch_size = 64\n",
    "Dimension = 16384\n",
    "# Learning_rate = 0.003\n",
    "Epochs = 100\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(lr_list), ))\n",
    "Tr_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(lr_list), ))\n",
    "Te_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Latency_lst = np.zeros((len(lr_list), ))\n",
    "avg_Inference_lst = np.zeros((len(lr_list), ))\n",
    "\n",
    "for idx in range(0, len(lr_list)):\n",
    "    Learning_rate = lr_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Learning rate', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Latency_lst, avg_Inference_lst], 'Learning rate', labels = 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ca64d-b54d-4984-9241-0973507a41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup OnlineHD model's hyper-parameters\n",
    "The_model = 'OnlineHD'\n",
    "Batch_size = 64\n",
    "Dimensions= 16384 \n",
    "Learning_rate = 1e-05\n",
    "# Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(ep_list), ))\n",
    "Tr_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(ep_list), ))\n",
    "Te_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Latency_lst = np.zeros((len(ep_list), ))\n",
    "avg_Inference_lst = np.zeros((len(ep_list), ))\n",
    "\n",
    "for idx in range(0, len(ep_list)):\n",
    "    Epochs = ep_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Epochs', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Latency_lst, avg_Inference_lst], 'Epochs', labels = 'time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be15a7b-491d-4f50-91e3-6cb35376f32f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NeuralHD model fine-tuning\n",
    "Keep the batch size at **64**, varying the dimentionality, learning rate, regenloop, fractiontoDrop, and finally the epochs.\n",
    "\n",
    "    dim_list = [300, 400, 512, 1024, 2048, \n",
    "                4096, 8192, 16384, 32768, 65536] ->\n",
    "    \n",
    "    lr_list = [0.01, 0.02, 0.03, 0.04, 0.05,\n",
    "               0.001, 0.002, 0.003, 0.004, 0.005, \n",
    "               0.0001, 0.0002, 0.0003, 0.0004, 0.0005, \n",
    "               0.00001, 0.00002, 0.00003, 0.00004, 0.00005] -> \n",
    "               \n",
    "               \n",
    "    regenloop = [2, 3, 4, 5, 6, 7, 8, 9, 10] ->\n",
    "    \n",
    "    fractiontoDrop = [0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "                      0.01, 0.02, 0.03, 0.04, 0.05] ->\n",
    "                      \n",
    "    ep_list = [4, 9, 16, 25, 36, \n",
    "               49, 64, 81, 100, 121, \n",
    "               144, 169, 196, 225, 256] -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e04c3-6b24-404b-b269-b14f4428f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup NeuralHD model's hyper-parameters\n",
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "# Dimension = 1024\n",
    "Learning_rate = 0.00001\n",
    "Regeneration = 25\n",
    "FractionDrop = 0.4\n",
    "Epochs = 16\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(dim_list), ))\n",
    "Tr_variance_lst = np.zeros((len(dim_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(dim_list), ))\n",
    "Te_variance_lst = np.zeros((len(dim_list), ))\n",
    "avg_Latency_lst = np.zeros((len(dim_list), ))\n",
    "avg_Inference_lst = np.zeros((len(dim_list), ))\n",
    "\n",
    "for idx in range(0, len(dim_list)):\n",
    "    Dimension = dim_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(dim_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Dimension', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(dim_list, [avg_Latency_lst, avg_Inference_lst], 'Dimension', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d3e32-61ef-4163-8b07-301ef4903e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 2048\n",
    "# Learning_rate = 0.0001\n",
    "Regeneration = 25\n",
    "FractionDrop = 0.4\n",
    "Epochs = 16\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(lr_list), ))\n",
    "Tr_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(lr_list), ))\n",
    "Te_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Latency_lst = np.zeros((len(lr_list), ))\n",
    "avg_Inference_lst = np.zeros((len(lr_list), ))\n",
    "\n",
    "for idx in range(0, len(lr_list)):\n",
    "    Learning_rate = lr_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Learning rate', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Latency_lst, avg_Inference_lst], 'Learning rate', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ea319-9b48-4dcb-8c2a-93dd89ad5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 2048\n",
    "Learning_rate = 0.001\n",
    "# Regeneration = 4\n",
    "FractionDrop = 0.1\n",
    "Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(regenloop), ))\n",
    "Tr_variance_lst = np.zeros((len(regenloop), ))\n",
    "avg_Te_acc_lst = np.zeros((len(regenloop), ))\n",
    "Te_variance_lst = np.zeros((len(regenloop), ))\n",
    "avg_Latency_lst = np.zeros((len(regenloop), ))\n",
    "avg_Inference_lst = np.zeros((len(regenloop), ))\n",
    "\n",
    "for idx in range(0, len(regenloop)):\n",
    "    Regeneration = regenloop[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(regenloop, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Regeneration', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(regenloop, [avg_Latency_lst, avg_Inference_lst], 'Regeneration', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1dbd26-4b5a-4362-8d2e-d30e90872d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 2048\n",
    "Learning_rate = 0.001\n",
    "Regeneration = 10\n",
    "# FractionDrop = 0.1\n",
    "Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(fractiontoDrop), ))\n",
    "Tr_variance_lst = np.zeros((len(fractiontoDrop), ))\n",
    "avg_Te_acc_lst = np.zeros((len(fractiontoDrop), ))\n",
    "Te_variance_lst = np.zeros((len(fractiontoDrop), ))\n",
    "avg_Latency_lst = np.zeros((len(fractiontoDrop), ))\n",
    "avg_Inference_lst = np.zeros((len(fractiontoDrop), ))\n",
    "\n",
    "for idx in range(0, len(fractiontoDrop)):\n",
    "    FractionDrop = fractiontoDrop[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(fractiontoDrop, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Fraction Drop', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(fractiontoDrop, [avg_Latency_lst, avg_Inference_lst], 'Fraction Drop', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e788293-7d74-499f-87cc-53199031d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 2048\n",
    "Learning_rate = 0.001\n",
    "Regeneration = 7\n",
    "FractionDrop = 0.4\n",
    "# Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(ep_list), ))\n",
    "Tr_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(ep_list), ))\n",
    "Te_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Latency_lst = np.zeros((len(ep_list), ))\n",
    "avg_Inference_lst = np.zeros((len(ep_list), ))\n",
    "\n",
    "for idx in range(0, len(ep_list)):\n",
    "    Epochs = ep_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Epochs', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Latency_lst, avg_Inference_lst], 'Epochs', labels = 'time')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecac8bf-2541-44e5-afd1-b93017958aae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP model fine-tuning\n",
    "Keep the batch size at **64**, varying the learning rate and epochs.\n",
    "    \n",
    "    lr_list = [0.01, 0.02, 0.03, 0.04, 0.05,\n",
    "               0.001, 0.002, 0.003, 0.004, 0.005, \n",
    "               0.0001, 0.0002, 0.0003, 0.0004, 0.0005, \n",
    "               0.00001, 0.00002, 0.00003, 0.00004, 0.00005] -> 0.0004\n",
    "               \n",
    "    ep_list = [4, 9, 16, 25, 36, \n",
    "               49, 64, 81, 100, 121] -> 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a604d-8794-42d6-be36-f18887e046ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup MLP model's hyper-parameters\n",
    "The_model = 'MLP'\n",
    "Batch_size = 64\n",
    "# Learning_rate = 0.002\n",
    "Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(lr_list), ))\n",
    "Tr_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(lr_list), ))\n",
    "Te_variance_lst = np.zeros((len(lr_list), ))\n",
    "avg_Latency_lst = np.zeros((len(lr_list), ))\n",
    "avg_Inference_lst = np.zeros((len(lr_list), ))\n",
    "\n",
    "for idx in range(0, len(lr_list)):\n",
    "    Learning_rate = lr_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Learning rate', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(lr_list, [avg_Latency_lst, avg_Inference_lst], 'Learning rate', labels = 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42025493-adf2-4cee-901d-f960fd4e12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup MLP model's hyper-parameters\n",
    "batchSz_lst = [1,2,4,8,16,32,64,128,256,512]\n",
    "\n",
    "The_model = 'MLP'\n",
    "# Batch_size = 64\n",
    "Learning_rate = 0.0004\n",
    "Epochs = 36\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(batchSz_lst), ))\n",
    "Tr_variance_lst = np.zeros((len(batchSz_lst), ))\n",
    "avg_Te_acc_lst = np.zeros((len(batchSz_lst), ))\n",
    "Te_variance_lst = np.zeros((len(batchSz_lst), ))\n",
    "avg_Latency_lst = np.zeros((len(batchSz_lst), ))\n",
    "avg_Inference_lst = np.zeros((len(batchSz_lst), ))\n",
    "\n",
    "for idx in range(0, len(batchSz_lst)):\n",
    "    Batch_size = batchSz_lst[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(batchSz_lst, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Batch size', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(batchSz_lst, [avg_Latency_lst, avg_Inference_lst], 'Batch size', labels = 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7f8b6-5118-428c-a2a9-8e7d48a0ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup MLP model's hyper-parameters\n",
    "The_model = 'MLP'\n",
    "Batch_size = 64\n",
    "Learning_rate = 0.0004\n",
    "# Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(ep_list), ))\n",
    "Tr_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Te_acc_lst = np.zeros((len(ep_list), ))\n",
    "Te_variance_lst = np.zeros((len(ep_list), ))\n",
    "avg_Latency_lst = np.zeros((len(ep_list), ))\n",
    "avg_Inference_lst = np.zeros((len(ep_list), ))\n",
    "\n",
    "for idx in range(0, len(ep_list)):\n",
    "    Epochs = ep_list[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Epochs', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(ep_list, [avg_Latency_lst, avg_Inference_lst], 'Epochs', labels = 'time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108658b3-103d-403a-954a-d27c31ee335a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Support Vector Classifier(SVM.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab57ab-ad54-42a4-b4ad-e5448eaf39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'SVM'\n",
    "results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                          repeat_times = Repeat_times, model_select = The_model,\n",
    "                          verbose = False, Classes = Classes, Features = Features, \n",
    "                          Dimensions = 4, Learning_rate = Learning_rate, \n",
    "                          Epochs = Epochs, Batch_size = Batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06421e41-5aca-44ac-bfa5-5572070c857b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Increasing epochs but keeping dim = 1024, OnlineHD or NeuralHD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc286a08-d97d-4f47-b12b-7e97ca0ff887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_OHD = [5,10,50,100,200,300,400,500]\n",
    "ep_NHD = [1,2,10,20,40,60,80,100]\n",
    "print(f'Epochs: {ep_OHD} \\t {ep_NHD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becade17-ded3-4114-98aa-09ebe8bd2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 1024\n",
    "Learning_rate = 0.001\n",
    "Regeneration = 4\n",
    "FractionDrop = 0.4\n",
    "# Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(ep_NHD), ))\n",
    "Tr_variance_lst = np.zeros((len(ep_NHD), ))\n",
    "avg_Te_acc_lst = np.zeros((len(ep_NHD), ))\n",
    "Te_variance_lst = np.zeros((len(ep_NHD), ))\n",
    "avg_Latency_lst = np.zeros((len(ep_NHD), ))\n",
    "avg_Inference_lst = np.zeros((len(ep_NHD), ))\n",
    "\n",
    "for idx in range(0, len(ep_NHD)):\n",
    "    Epochs = ep_NHD[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(ep_NHD, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Epochs', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(ep_NHD, [avg_Latency_lst, avg_Inference_lst], 'Epochs', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc85908-d0c5-4c19-9cc4-89108aa2fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup OnlineHD model's hyper-parameters\n",
    "The_model = 'OnlineHD'\n",
    "Batch_size = 64\n",
    "Dimensions= 1024 \n",
    "Learning_rate = 1e-05\n",
    "# Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(ep_OHD), ))\n",
    "Tr_variance_lst = np.zeros((len(ep_OHD), ))\n",
    "avg_Te_acc_lst = np.zeros((len(ep_OHD), ))\n",
    "Te_variance_lst = np.zeros((len(ep_OHD), ))\n",
    "avg_Latency_lst = np.zeros((len(ep_OHD), ))\n",
    "avg_Inference_lst = np.zeros((len(ep_OHD), ))\n",
    "\n",
    "for idx in range(0, len(ep_OHD)):\n",
    "    Epochs = ep_OHD[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(ep_OHD, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Epochs', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(ep_OHD, [avg_Latency_lst, avg_Inference_lst], 'Epochs', labels = 'time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e985b-1c20-46f0-9eb3-75c52aaa7a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cb0ec-56a4-4782-b67c-9fe4a039b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_models = ['SVM', 'MLP', 'OnlineHD', 'NeuralHD']\n",
    "accuracies = [89.3265, 96.0195, 95.0221, 95.2724]\n",
    "training_latencies = [1.2818, 19.8972, 13.1704, 49.7349]\n",
    "inference_latencies = [3.3513, 0.1986, 0.2481, 0.1009]\n",
    "\n",
    "plt.bar(All_models, accuracies)\n",
    "plt.title('Accuracy by models')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(All_models, training_latencies)\n",
    "plt.title('Training Time Latency by models')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(All_models, inference_latencies)\n",
    "plt.title('Inference Time by models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130072a-27d6-4dc7-9861-602cdf55050d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## More experiments and tasks on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc9f22-ca5f-46b4-9851-8ce07d847f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenloops = [2,5,10,13,15,20,25,31]\n",
    "\n",
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimension = 2048\n",
    "Learning_rate = 0.001\n",
    "# Regeneration = 4\n",
    "FractionDrop = 0.4\n",
    "Epochs = 32\n",
    "\n",
    "# Y_axis\n",
    "avg_Tr_acc_lst = np.zeros((len(regenloops), ))\n",
    "Tr_variance_lst = np.zeros((len(regenloops), ))\n",
    "avg_Te_acc_lst = np.zeros((len(regenloops), ))\n",
    "Te_variance_lst = np.zeros((len(regenloops), ))\n",
    "avg_Latency_lst = np.zeros((len(regenloops), ))\n",
    "avg_Inference_lst = np.zeros((len(regenloops), ))\n",
    "\n",
    "for idx in range(0, len(regenloops)):\n",
    "    Regeneration = regenloops[idx]\n",
    "    results = Models_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                              repeat_times = Repeat_times, model_select = The_model,\n",
    "                              verbose = False, Classes = Classes, Features = Features, \n",
    "                              Dimensions = Dimension, Learning_rate = Learning_rate, \n",
    "                              Epochs = Epochs, Batch_size = Batch_size,\n",
    "                              Regeneration = Regeneration, \n",
    "                              FractionDrop = FractionDrop)\n",
    "    \n",
    "    avg_Tr_acc_lst[idx] = results[0]\n",
    "    Tr_variance_lst[idx] = results[1]\n",
    "    avg_Te_acc_lst[idx] = results[2]\n",
    "    Te_variance_lst[idx] = results[3]\n",
    "    avg_Latency_lst[idx] = results[4]\n",
    "    avg_Inference_lst[idx] = results[5]\n",
    "\n",
    "\n",
    "print(Evaluation_Visualizer(regenloops, [avg_Tr_acc_lst, avg_Te_acc_lst, Tr_variance_lst, Te_variance_lst], 'Regeneration', labels = 'acc'))\n",
    "print(Evaluation_Visualizer(regenloops, [avg_Latency_lst, avg_Inference_lst], 'Regeneration', labels = 'time')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd126015-cb47-48eb-b1d1-51ddf4cf2e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
