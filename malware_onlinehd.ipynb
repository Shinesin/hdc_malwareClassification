{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a627d7ce-ba93-4f21-a6e3-246e985d2e91",
   "metadata": {},
   "source": [
    "# Malware Classification : Evaluation and Fine-tuning on HD models\n",
    "## Xiangsheng Gu & Robert Armen Missirian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c15612-ffd0-4482-bec1-29764e251506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from OnlineHD_model import *\n",
    "from NeuralHD_model import *\n",
    "from malware_data_preprocessing import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dde6459-4545-432d-9c9c-569603e7ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:\n",
      "x_train -> (8151, 257)\tx_test -> (2717, 257)\n",
      "y_train -> (8151,)\ty_test -> (2717,)\n",
      "This dataset contains 9 classes, and 257 features.\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_dataset(\"Microsoft Challenge BIG 2015\")\n",
    "Classes = 9\n",
    "Features = 257\n",
    "print(f'Shape of input data:\\nx_train -> {x_train.shape}\\tx_test -> {x_test.shape}')\n",
    "print(f'y_train -> {y_train.shape}\\ty_test -> {y_test.shape}')\n",
    "print(f'This dataset contains {Classes} classes, and {Features} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e208efa0-a085-41f7-a840-590d7224aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryAccuracy(y, ypred, train_or_test = 'training', report = False):\n",
    "    lst = torch.eq(y, ypred)\n",
    "    count = 0\n",
    "    for i in lst:\n",
    "        if i == True:\n",
    "            count += 1\n",
    "    accuracy = count/len(lst) * 100\n",
    "    if report == True:\n",
    "        print(f'The {train_or_test} accuracy is about: {round(accuracy, 2)}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def HDC_Model_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                repeat_times, model_select,\n",
    "                Classes, Features, Dimensions,\n",
    "                Learning_rate, Epochs, Batch_size,\n",
    "                Regeneration = 5,FractionDrop = 0.1):\n",
    "    \n",
    "    # For the training set\n",
    "    x_train = torch.from_numpy(x_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    # For the testing set\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    \n",
    "    # The Online-HD model\n",
    "    if model_select == 'OnlineHD':\n",
    "        model = OnlineHD(classes = Classes, \n",
    "                         features = Features, \n",
    "                         dim = Dimensions)\n",
    "    # The Neural-HD model\n",
    "    if model_select == 'NeuralHD':\n",
    "        model = NeuralHD(classes = Classes, \n",
    "                         features = Features, \n",
    "                         dim = Dimensions, \n",
    "                         batch_size = Batch_size,\n",
    "                         trainopt = 3,\n",
    "                         bestinclass = True)\n",
    "    \n",
    "    # Optional: For both training and testing sets, check if gpu/cuda is available to use\n",
    "    '''\n",
    "    if torch.cuda.is_available() and model_select == 'OnlineHD':\n",
    "        print(f'Training on {torch.cuda.get_device_name(0)}\\n')\n",
    "        model = model.to('cuda')\n",
    "        x_train = x_train.to('cuda')\n",
    "        y_train = y_train.to('cuda')\n",
    "        x_test = x_test.to('cuda')\n",
    "        y_test = y_test.to('cuda')\n",
    "    '''\n",
    "    print('Training on 12th Gen Intel Core i9-12900k')\n",
    "    \n",
    "    # Lists for storing acc scores and time measurements in seconds\n",
    "    Tr_lst = list()\n",
    "    Te_lst = list()\n",
    "    Tr_latency_lst = list()\n",
    "    Inference_time_lst = list()\n",
    "    \n",
    "    for each_time in tqdm(range(repeat_times)): \n",
    "        time.sleep(2) # here is why time per iter in larger\n",
    "    \n",
    "        # set up training latency and inference time\n",
    "        training_start = 0.0\n",
    "        training_end = 0.0\n",
    "        infer_start = 0.0\n",
    "        infer_end = 0.0\n",
    "        \n",
    "        # For the training set\n",
    "        if model_select == 'NeuralHD':\n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, x_test, y_train, y_test, \n",
    "                      epochs = Epochs, \n",
    "                      regenloops = Regeneration, \n",
    "                      fractionToDrop = FractionDrop)\n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "        \n",
    "        if model_select == 'OnlineHD':\n",
    "            # start training latency\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.fit(x_train, y_train, \n",
    "                      encoded = False, \n",
    "                      lr = Learning_rate, \n",
    "                      epochs = Epochs, \n",
    "                      batch_size = Batch_size, \n",
    "                      one_pass_fit = False)\n",
    "            \n",
    "            # complete training\n",
    "            training_end = time.time()\n",
    "        \n",
    "        training_latency_sec = training_end - training_start\n",
    "        Tr_latency_lst.append(training_latency_sec)\n",
    "        \n",
    "        # start inference time\n",
    "        infer_start = time.time()  \n",
    "        # prediction\n",
    "        ypred = model(x_train)\n",
    "        # prediction completed\n",
    "        infer_end = time.time()\n",
    "        inference_time_sec = infer_end - infer_start\n",
    "        Inference_time_lst.append(inference_time_sec)\n",
    "        \n",
    "        Tr_accuracy = binaryAccuracy(y_train, ypred, \n",
    "                                     train_or_test = 'training', \n",
    "                                     report = False)\n",
    "        Tr_lst.append(Tr_accuracy)\n",
    "        \n",
    "        # For the testing set\n",
    "        ypred = model(x_test)\n",
    "        Te_accuracy = binaryAccuracy(y_test, ypred, \n",
    "                                     train_or_test = 'testing', \n",
    "                                     report = False)\n",
    "        Te_lst.append(Te_accuracy)\n",
    "    \n",
    "    # For the training set\n",
    "    # Tr_max = max(Tr_lst)\n",
    "    Tr_mean = np.mean(Tr_lst)\n",
    "    Tr_variance = np.var(Tr_lst)\n",
    "    \n",
    "    # For the testing set\n",
    "    # Te_max = max(Te_lst)\n",
    "    Te_mean = np.mean(Te_lst)\n",
    "    Te_variance = np.var(Te_lst)\n",
    "    \n",
    "    # For training latency and inference time\n",
    "    avg_training_latency = np.mean(Tr_latency_lst)\n",
    "    avg_inference_time = np.mean(Inference_time_lst)\n",
    "    \n",
    "    \n",
    "    # The report\n",
    "    print(f'The applied model is {model_select}, and its hyper-parameters are set as:\\n')\n",
    "    print(f'Classes -> {Classes} \\t Features -> {Features} \\t Dimensions -> {Dimensions}')\n",
    "    print(f'Learning Rate -> {Learning_rate} \\t Epochs -> {Epochs} \\t Batch size -> {Batch_size}\\n')\n",
    "    \n",
    "    if model_select == 'NeuralHD':\n",
    "        print(f'Regeneration -> {Regeneration} \\t FractionDrop -> {FractionDrop}\\n')\n",
    "        \n",
    "    if repeat_times > 1:\n",
    "        print(f'*****For {repeat_times} times of iteration*****\\n') \n",
    "        print(f'The variance on the training set:\\n{Tr_variance}\\n\\nThe variance on the testing set:\\n{Te_variance}\\n')\n",
    "        \n",
    "    # print(f'The maximum accuracy on the training set:\\n{Tr_max}\\n\\nThe maximum accuracy on the testing set:\\n{Te_max}\\n')\n",
    "    print(f'The average accuracy on the training set:\\n{Tr_mean}\\n\\nThe average accuracy on the testing set:\\n{Te_mean}\\n')\n",
    "    print(f'The average training latency:\\n{avg_training_latency} seconds\\n\\nThe average inference time:\\n{avg_inference_time} seconds\\n')\n",
    "    \n",
    "    return Tr_mean, Te_mean, avg_training_latency, avg_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59957d7c-8ac7-4934-9cae-e8298e1e95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model's hyper-parameters\n",
    "The_model = 'NeuralHD'\n",
    "Batch_size = 64\n",
    "Dimensions = 1024\n",
    "Learning_rate = 0.02\n",
    "Repeat_times = 10\n",
    "Epochs = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89685acb-6cad-4cb6-9964-588aca542845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 12th Gen Intel Core i9-12900k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:58<00:00, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The applied model is NeuralHD, and its hyper-parameters are set as:\n",
      "\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 1024\n",
      "Learning Rate -> 0.02 \t Epochs -> 55 \t Batch size -> 64\n",
      "\n",
      "Regeneration -> 5 \t FractionDrop -> 0.1\n",
      "\n",
      "For 10 times of iteration:\n",
      "\n",
      "The variance on the training set:\n",
      "0.08218691363801119\n",
      "\n",
      "The variance on the testing set:\n",
      "0.022541044953536416\n",
      "\n",
      "The average accuracy on the training set:\n",
      "98.92773892773894\n",
      "\n",
      "The average accuracy on the testing set:\n",
      "96.55502392344496\n",
      "\n",
      "The average training latency:\n",
      "21.83267560005188 seconds\n",
      "\n",
      "The average inference time:\n",
      "0.022291135787963868 seconds\n",
      "\n",
      "98.92773892773894 96.55502392344496 21.83267560005188 0.022291135787963868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimize the dimentionality, learning rate, regenloop, fractiontoDrop, epochs, while keep batch size at 64\n",
    "# batchSz_lst = [1,2,4,8,16,32,64,128,256,512] -> 64\n",
    "# dim_list = [2,4,8,16,32,64,128,256,512,1024,2048,4096] -> 2048\n",
    "'''\n",
    "lr_list = [0.1, 0.2, 0.3, \n",
    "           0.01, 0.02, 0.03, \n",
    "           0.001, 0.002, 0.003, \n",
    "           0.0001, 0.0002, 0.0003, \n",
    "           0.00001, 0.00002, 0.00003, \n",
    "           0.000001, 0.000002, 0.000003] -> 0.002\n",
    "'''\n",
    "# ep_list = [1,2,4,8,16,32,64,128] -> 64\n",
    "\n",
    "\n",
    "avg_training_accuracy, avg_testing_accuracy, avg_training_latency, avg_inference_time = HDC_Model_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                                                                                                           repeat_times = Repeat_times, model_select = The_model, \n",
    "                                                                                                           Classes = Classes, Features = Features, \n",
    "                                                                                                           Dimensions = Dimensions, \n",
    "                                                                                                           Learning_rate = Learning_rate, \n",
    "                                                                                                           Epochs = Epochs, \n",
    "                                                                                                           Batch_size = Batch_size)\n",
    "\n",
    "print(avg_training_accuracy, avg_testing_accuracy, avg_training_latency, avg_inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ced4d56-1fa9-404e-a1a9-b032edc8e493",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23720/1356835073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mFractionDrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdim_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mDimensions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     HD_Analyzer(x_train, x_test, y_train, y_test, \n",
      "\u001b[1;31mNameError\u001b[0m: name 'dim_list' is not defined"
     ]
    }
   ],
   "source": [
    "# optimize the dimentionality, learning rate, regenloop, fractiontoDrop, epochs, while keep batch size at 64\n",
    "# batchSz_lst = [1,2,4,8,16,32,64,128,256,512] -> 64\n",
    "# dim_list = [2,4,8,16,32,64,128,256,512,1024,2048] -> 1024\n",
    "'''\n",
    "lr_list = [0.1, 0.2, 0.3, \n",
    "           0.01, 0.02, 0.03, \n",
    "           0.001, 0.002, 0.003, \n",
    "           0.0001, 0.0002, 0.0003, \n",
    "           0.00001, 0.00002, 0.00003, \n",
    "           0.000001, 0.000002, 0.000003] -> 0.02\n",
    "'''\n",
    "# regenloop_lst = [1,2,3,4,5,6,7,8,16]\n",
    "# setup model's hyper-parameters\n",
    "The_model = 'NeuralHD'\n",
    "Repeat_times = 10\n",
    "Classes = 9\n",
    "Features = 257\n",
    "Batch_size = 64\n",
    "Epochs = 10\n",
    "# Dimensions = 1024\n",
    "Learning_rate = 0.02\n",
    "Regeneration = 5\n",
    "FractionDrop = 0.1\n",
    "\n",
    "for dim in dim_list:\n",
    "    Dimensions = dim\n",
    "    HD_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                repeat_times = Repeat_times, model_select = The_model, \n",
    "                Classes = Classes, Features = Features, Dimensions = Dimensions,\n",
    "                Learning_rate = Learning_rate, Epochs = Epochs, \n",
    "                Batch_size = Batch_size, Regeneration = Regeneration, FractionDrop = FractionDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5e89a-9e08-4246-a54f-82586c30c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:\n",
      "x_train -> (8151, 257)\tx_test -> (2717, 257)\n",
      "y_train -> (8151,)\ty_test -> (2717,)\n",
      "\n",
      "The Report\n",
      "\n",
      "The applied model is NeuralHD, and its hyper-parameters are set as:\n",
      "\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 1024\n",
      "Learning Rate -> 0.1 \t Epochs -> 10 \t Batch size -> 64\n",
      "\n",
      "Regeneration -> 0 \t FractionDrop -> 0.002\n",
      "\n",
      "For 10 times of iteration:\n",
      "\n",
      "The variance on the training set: 47.612177709227424\n",
      "The variance on the testing set: 51.26700585701418\n",
      "\n",
      "The maximum accuracy on the training set: 96.60164397006503\n",
      "The maximum accuracy on the testing set: 94.77364740522636\n",
      "\n",
      "The average accuracy on the training set: 91.9273708747393\n",
      "The average accuracy on the testing set: 90.34965034965035\n",
      "\n",
      "Shape of input data:\n",
      "x_train -> (8151, 257)\tx_test -> (2717, 257)\n",
      "y_train -> (8151,)\ty_test -> (2717,)\n",
      "\n",
      "The Report\n",
      "\n",
      "The applied model is NeuralHD, and its hyper-parameters are set as:\n",
      "\n",
      "Classes -> 9 \t Features -> 257 \t Dimensions -> 1024\n",
      "Learning Rate -> 0.1 \t Epochs -> 10 \t Batch size -> 64\n",
      "\n",
      "Regeneration -> 1 \t FractionDrop -> 0.002\n",
      "\n",
      "For 10 times of iteration:\n",
      "\n",
      "The variance on the training set: 2.9573020139240542\n",
      "The variance on the testing set: 2.5764522752299555\n",
      "\n",
      "The maximum accuracy on the training set: 97.58311863575021\n",
      "The maximum accuracy on the testing set: 95.47294810452705\n",
      "\n",
      "The average accuracy on the training set: 96.07655502392342\n",
      "The average accuracy on the testing set: 94.32462274567538\n",
      "\n",
      "Shape of input data:\n",
      "x_train -> (8151, 257)\tx_test -> (2717, 257)\n",
      "y_train -> (8151,)\ty_test -> (2717,)\n",
      "\n",
      "The Report\n"
     ]
    }
   ],
   "source": [
    "# optimize the dimentionality, learning rate, regenloop, fractiontoDrop, epochs, while keep batch size at 64\n",
    "# batchSz_lst = [1,2,4,8,16,32,64,128,256,512] -> 64\n",
    "# dim_list = [2,4,8,16,32,64,128,256,512,1024,2048]\n",
    "'''\n",
    "lr_list = [0.1, 0.2, 0.3, \n",
    "           0.01, 0.02, 0.03, \n",
    "           0.001, 0.002, 0.003, \n",
    "           0.0001, 0.0002, 0.0003, \n",
    "           0.00001, 0.00002, 0.00003, \n",
    "           0.000001, 0.000002, 0.000003] -> 0.1\n",
    "\n",
    "FractionDrop_lst = [0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "                    0.01, 0.02, 0.03, 0.04, 0.05, \n",
    "                    0.001, 0.002, 0.003, 0.004, 0.005] ->0.002\n",
    "'''\n",
    "regenloop_lst = [0,1,2,3,4,5,6,7,8,16]\n",
    "# setup model's hyper-parameters\n",
    "The_model = 'NeuralHD'\n",
    "Repeat_times = 10\n",
    "Classes = 9\n",
    "Features = 257\n",
    "Batch_size = 64\n",
    "Epochs = 10\n",
    "Dimensions = 1024\n",
    "Learning_rate = 0.1\n",
    "# Regeneration = 5\n",
    "FractionDrop = 0.002\n",
    "\n",
    "for Regeneration in regenloop_lst:\n",
    "    HD_Analyzer(x_train, x_test, y_train, y_test, \n",
    "                repeat_times = Repeat_times, model_select = The_model, \n",
    "                Classes = Classes, Features = Features, Dimensions = Dimensions,\n",
    "                Learning_rate = Learning_rate, Epochs = Epochs, \n",
    "                Batch_size = Batch_size, Regeneration = Regeneration, FractionDrop = FractionDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daaac53-d15c-42ea-9b3e-0efd7f4d68ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
